{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":97258,"sourceType":"competition"},{"sourceId":11440765,"sourceType":"datasetVersion","datasetId":7166820}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:25:41.351514Z","iopub.execute_input":"2025-04-19T12:25:41.351828Z","iopub.status.idle":"2025-04-19T12:25:41.703806Z","shell.execute_reply.started":"2025-04-19T12:25:41.351802Z","shell.execute_reply":"2025-04-19T12:25:41.702977Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/ringtone/phone-ringtone-telephone-324474.mp3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install -U langchain langchain-core langchain-community langchain-openai \\\n  faiss-cpu google-cloud-texttospeech pydub reportlab gradio langgraph --quiet\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:25:41.705153Z","iopub.execute_input":"2025-04-19T12:25:41.705532Z","iopub.status.idle":"2025-04-19T12:26:08.226364Z","shell.execute_reply.started":"2025-04-19T12:25:41.705504Z","shell.execute_reply":"2025-04-19T12:26:08.224743Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m433.9/433.9 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m188.1/188.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m145.2/145.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m647.0/647.0 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# ğŸ§  Project Title: \"Global MedAssist: Multi-Agent System for Travel Health Insurance Operations\"\n# ğŸ©º Domain: Healthcare Operations & Travel Insurance\n## ğŸŒ Real-World Scenario:\n\nYour company provides health coverage for travelers around the world. When clients experience medical issues abroadâ€”ranging from minor outpatient consultations to critical emergency admissionsâ€”a coordinated response is needed. Currently, a human operations agent manages the workflow. This project proposes a multi-agent system to automate and streamline that process. Furthermore, adds a LLM in form of a smart phone app that would speed the contact between the aptient and the insurance company in terms of commmunication, referral to Hospitals within our network and sending medical reports and images of the injuries so that our medical team can assess them. ","metadata":{}},{"cell_type":"markdown","source":"# Capstone Project: Multi-Agent System for Travel Health Insurance Operations\n\n## Objective:\nTo build a simulated multi-agent system that replaces a human operations agent in a global travel health insurance company. This system assists clients who encounter medical issues while traveling abroad.\n","metadata":{}},{"cell_type":"markdown","source":"# -----------------------------------\n# ğŸ”§ SECTION 1: Agent System Definition\n# -----------------------------------\n\n## 1.1 Agent Roles and Responsibilities","metadata":{}},{"cell_type":"code","source":"from collections import OrderedDict\n\n# 1.1 Agent Roles and Responsibilities\nagent_roles = OrderedDict([\n    (\"ClientInteractionAgent\", \n     \"First point of contact for the traveler (client). Captures incident details via multilingual chat or voice, \"\n     \"identifies the client and policy using name, ID, or geolocation, and triggers the triage process with a unique case ID. \"\n     \"Tech: NLP, Google Cloud TTS, contextual empathy prompts.\"),\n    \n    (\"TriageMedicalAssessmentAgent\", \n     \"Classifies the case based on urgency and symptoms. Evaluates symptom severity using clinical rule sets, \"\n     \"determines care level (outpatient, ER, inpatient), and escalates life-threatening cases to the Repatriation Agent. \"\n     \"Tech: Decision trees, symptom checkers, rule-based protocols.\"),\n    \n    (\"ProviderNetworkAgent\", \n     \"Finds suitable nearby medical facilities based on location, language, specialty, and availability. Sends appointment requests, \"\n     \"confirms bookings, and logs provider responses with estimated wait times. \"\n     \"Tech: Fuzzy location matching, mocked RAG for provider directories.\"),\n    \n    (\"MedicalDocumentationAgent\", \n     \"Collects, translates, and formats medical documents including discharge summaries, invoices, and diagnostics. Translates reports if necessary, \"\n     \"and extracts key data for policy and decision validation. \"\n     \"Tech: OCR, translation APIs, entity extraction.\"),\n    \n    (\"PolicyValidationAgent\", \n     \"Verifies if the requested treatment is covered by the clientâ€™s policy. Retrieves policy terms, matches treatment details, \"\n     \"and flags exclusions, co-pays, or missing documentation. \"\n     \"Tech: Knowledge graph queries, mock policy lookup APIs.\"),\n    \n    (\"RepatriationPlannerAgent\", \n     \"Plans and coordinates the clientâ€™s transport back home. Assesses feasibility (commercial flight, air ambulance, ground transport), \"\n     \"coordinates with local and home providers, and ensures medical escort and fit-to-fly documentation. \"\n     \"Tech: Scenario planning, cost estimation, real-time logistics.\"),\n    \n    (\"MedicalDecisionAgent\", \n     \"Supports complex clinical and operational decisions. Offers second opinions, validates provider suitability, \"\n     \"and interfaces with clinical guidelines and expert systems. \"\n     \"Tech: Rule-based reasoning, LLM summarization.\"),\n    \n    (\"ComplianceConsentAgent\", \n     \"Handles legal and consent-related tasks. Ensures clients have accepted data sharing terms, generates e-consent forms, \"\n     \"and logs compliance for applicable jurisdictions (e.g., GDPR, HIPAA). \"\n     \"Tech: Template generation, e-signatures, legal compliance logic.\"),\n    \n    (\"CountryCareLevelAgent\", \n     \"Determines the risk level of the country (Level 1â€“3). Triggers escalation to the medical team if the client is admitted in a Level 3 country. \"\n     \"Also handles special cases like ICU admissions or multi-victim incidents.\"),\n    \n    (\"OrchestratorAgent\", \n     \"Manages workflow, routes tasks between agents, and monitors overall progress. Handles exceptions, timeouts, \"\n     \"and logs KPIs for comparison with human workflows. \"\n     \"Tech: LangGraph orchestration, event logging, retry policies.\")\n])\n\n# Optional: Validate agent roles\nassert \"ClientInteractionAgent\" in agent_roles\nassert len(agent_roles) == 10\n\n# Print out each agent and their role with numbering\nfor idx, (agent, task) in enumerate(agent_roles.items(), 1):\n    print(f\"\\n{idx}. ğŸ¤– {agent}:\")\n    print(f\"   â” {task}\")\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:26:08.228412Z","iopub.execute_input":"2025-04-19T12:26:08.228838Z","iopub.status.idle":"2025-04-19T12:26:08.240046Z","shell.execute_reply.started":"2025-04-19T12:26:08.228804Z","shell.execute_reply":"2025-04-19T12:26:08.239108Z"}},"outputs":[{"name":"stdout","text":"\n1. ğŸ¤– ClientInteractionAgent:\n   â” First point of contact for the traveler (client). Captures incident details via multilingual chat or voice, identifies the client and policy using name, ID, or geolocation, and triggers the triage process with a unique case ID. Tech: NLP, Google Cloud TTS, contextual empathy prompts.\n\n2. ğŸ¤– TriageMedicalAssessmentAgent:\n   â” Classifies the case based on urgency and symptoms. Evaluates symptom severity using clinical rule sets, determines care level (outpatient, ER, inpatient), and escalates life-threatening cases to the Repatriation Agent. Tech: Decision trees, symptom checkers, rule-based protocols.\n\n3. ğŸ¤– ProviderNetworkAgent:\n   â” Finds suitable nearby medical facilities based on location, language, specialty, and availability. Sends appointment requests, confirms bookings, and logs provider responses with estimated wait times. Tech: Fuzzy location matching, mocked RAG for provider directories.\n\n4. ğŸ¤– MedicalDocumentationAgent:\n   â” Collects, translates, and formats medical documents including discharge summaries, invoices, and diagnostics. Translates reports if necessary, and extracts key data for policy and decision validation. Tech: OCR, translation APIs, entity extraction.\n\n5. ğŸ¤– PolicyValidationAgent:\n   â” Verifies if the requested treatment is covered by the clientâ€™s policy. Retrieves policy terms, matches treatment details, and flags exclusions, co-pays, or missing documentation. Tech: Knowledge graph queries, mock policy lookup APIs.\n\n6. ğŸ¤– RepatriationPlannerAgent:\n   â” Plans and coordinates the clientâ€™s transport back home. Assesses feasibility (commercial flight, air ambulance, ground transport), coordinates with local and home providers, and ensures medical escort and fit-to-fly documentation. Tech: Scenario planning, cost estimation, real-time logistics.\n\n7. ğŸ¤– MedicalDecisionAgent:\n   â” Supports complex clinical and operational decisions. Offers second opinions, validates provider suitability, and interfaces with clinical guidelines and expert systems. Tech: Rule-based reasoning, LLM summarization.\n\n8. ğŸ¤– ComplianceConsentAgent:\n   â” Handles legal and consent-related tasks. Ensures clients have accepted data sharing terms, generates e-consent forms, and logs compliance for applicable jurisdictions (e.g., GDPR, HIPAA). Tech: Template generation, e-signatures, legal compliance logic.\n\n9. ğŸ¤– CountryCareLevelAgent:\n   â” Determines the risk level of the country (Level 1â€“3). Triggers escalation to the medical team if the client is admitted in a Level 3 country. Also handles special cases like ICU admissions or multi-victim incidents.\n\n10. ğŸ¤– OrchestratorAgent:\n   â” Manages workflow, routes tasks between agents, and monitors overall progress. Handles exceptions, timeouts, and logs KPIs for comparison with human workflows. Tech: LangGraph orchestration, event logging, retry policies.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# ğŸ§  SECTION 2: Prompt Templates with Persona and Format\n","metadata":{}},{"cell_type":"code","source":"# ----------------------------------------\n# ğŸ§  SECTION 2: Prompt Templates with Persona and Format + Enhancements\n# ----------------------------------------\n\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom collections import OrderedDict\nimport json\nimport yaml\n\n# Define enhanced prompts with SSML and persona\nprompt_templates = OrderedDict()\n\nprompt_templates['ClientInteractionAgent'] = ChatPromptTemplate.from_template(\n    \"\"\"<speak>\n        <prosody rate=\"medium\" pitch=\"+2st\">\n            You are a friendly and empathetic insurance assistant.\n            â€¢ Greet the traveler warmly.\n            â€¢ Collect the following information:\n                - Symptoms\n                - Current location (city and country)\n                - Personal identifiers (name or ID)\n                - Travel dates\n            â€¢ Use NLP to infer urgency and classify the case:\n                - outpatient\n                - emergency\n            â€¢ Generate a unique case ID and trigger triage.\n            â€¢ Output Format: JSON with fields: case_id, name, symptoms, location, urgency, classification.\n        </prosody>\n    </speak>\"\"\"\n)\n\nprompt_templates['TriageMedicalAssessmentAgent'] = ChatPromptTemplate.from_template(\n    \"\"\"You are a precise and empathetic triage assistant.\n    â€¢ Evaluate the symptoms and medical history using clinical rules.\n    â€¢ Classify urgency: outpatient, ER, or inpatient.\n    â€¢ Escalate directly to Repatriation Agent for life-threatening cases.\n    â€¢ Ask if symptoms began before the trip.\n    â€¢ Output Format: JSON with fields: urgency, recommended_care, pre_existing_flag, escalate_flag.\"\"\"\n)\n\nprompt_templates['ProviderNetworkAgent'] = ChatPromptTemplate.from_template(\n    \"\"\"You are a provider network specialist helping travelers find care.\n    â€¢ Find the best matching provider based on:\n        - Location\n        - Specialty\n        - Language\n        - Safety rating\n    â€¢ Query using: `hospital_network_lookup(location)`.\n    â€¢ If a facility is blacklisted, trigger escalation.\n    â€¢ Output Format: JSON with fields: hospital_name, address, specialty, safety_rating, blacklist_flag, contact_info.\"\"\"\n)\n\nprompt_templates['MedicalDocumentationAgent'] = ChatPromptTemplate.from_template(\n    \"\"\"You are responsible for collecting and processing medical documents.\n    â€¢ Request discharge summary, invoice, diagnostics, and Fit-to-Fly certificate.\n    â€¢ Translate documents if not in the client's preferred language.\n    â€¢ Extract diagnosis and treatment data.\n    â€¢ Output Format: JSON with fields: report_status, fit_to_fly, diagnosis_summary, compliance_notes.\"\"\"\n)\n\nprompt_templates['PolicyValidationAgent'] = ChatPromptTemplate.from_template(\n    \"\"\"You are the policy validation expert.\n    â€¢ Validate coverage for the case using `policy_checker_tool`.\n    â€¢ Check:\n        - Incident type (accident/illness)\n        - Coverage limits\n        - Exclusions\n        - Travel date validity\n        - Blacklisted providers\n    â€¢ Output Format: JSON with fields: is_covered, exclusions, incident_type, validation_notes, blacklisted_provider.\"\"\"\n)\n\nprompt_templates['RepatriationPlannerAgent'] = ChatPromptTemplate.from_template(\n    \"\"\"You plan medical repatriation for international travelers.\n    â€¢ Choose optimal transport: air ambulance, stretcher, WCHC/WCHR/WCHS, escort (nurse/doctor), ground transport.\n    â€¢ If escort or Level 3 country, notify ACC immediately.\n    â€¢ Output Format: JSON with fields: transport_mode, escort_required, acc_notified, fit_to_fly_required, questionnaire_sent.\"\"\"\n)\n\nprompt_templates['MedicalDecisionAgent'] = ChatPromptTemplate.from_template(\n    \"\"\"You are simulating the medical team's judgment.\n    â€¢ Review diagnosis and treatment plan.\n    â€¢ Approve, revise, or escalate based on clinical appropriateness.\n    â€¢ Consult ACC for Level 3 care or high-risk profiles.\n    â€¢ Output Format: JSON with fields: decision, notes, escalate_flag, approved_facility.\"\"\"\n)\n\nprompt_templates['ComplianceConsentAgent'] = ChatPromptTemplate.from_template(\n    \"\"\"You ensure GDPR and HIPAA compliance during the case.\n    â€¢ Confirm that the client has consented to:\n        - Data sharing with hospitals and ACC\n        - Repatriation arrangements\n    â€¢ Generate encrypted approval log using `Fernet`.\n    â€¢ Output Format: JSON with fields: consent_granted, timestamp, encrypted_log_key, jurisdiction.\"\"\"\n)\n\nprompt_templates['CountryCareLevelAgent'] = ChatPromptTemplate.from_template(\n    \"\"\"You assign the care level of the client's current country.\n    â€¢ Levels:\n        - Level 1: High quality\n        - Level 2: Moderate\n        - Level 3: Low (trigger escalation if admitted)\n    â€¢ Notify ACC and log to DCR tracker if Level 3 and admitted.\n    â€¢ Output Format: JSON with fields: care_level, notify_paris_acc, dcr_logged, msc_contact_due.\"\"\"\n)\n\nprompt_templates['OrchestratorAgent'] = ChatPromptTemplate.from_template(\n    \"\"\"You orchestrate the entire case workflow.\n    â€¢ Route the case through the following agents in sequence:\n        - ClientInteraction â†’ Triage â†’ Provider â†’ Docs â†’ Policy â†’ Medical Decision â†’ Repatriation â†’ Consent\n    â€¢ Monitor agent timing, failure states, and escalation points.\n    â€¢ Log progress to the KPI dashboard and simulate human-AI comparison.\n    â€¢ Output Format: JSON with fields: completed_steps, timing_stats, escalation_flags, ab_test_summary.\"\"\"\n)\n\n# ------------------------------------------------\n# ğŸ“¤ EXPORTS: JSON and YAML for UI or config usage\n# ------------------------------------------------\n\n# Extract the actual prompt strings\njson_data = {\n    k: v.messages[0].prompt.template\n    for k, v in prompt_templates.items()\n}\n\n# Export to JSON\nwith open(\"agent_prompts.json\", \"w\") as json_file:\n    json.dump(json_data, json_file, indent=2)\n\n# Export to YAML\nwith open(\"agent_prompts.yaml\", \"w\") as yaml_file:\n    yaml.dump(json_data, yaml_file, sort_keys=False)\n\n# ------------------------------------------------\n# âš™ï¸ LangGraph-Compatible Prompt Wrappers\n# ------------------------------------------------\ndef create_agent_node(agent_name):\n    def agent_node(state):\n        prompt = prompt_templates[agent_name].format_messages(**state)\n        # You could also add TTS generation or API calls here\n        return {\"response\": prompt}\n    return agent_node\n\n# Example usage:\nclient_interaction_node = create_agent_node(\"ClientInteractionAgent\")\ntriage_node = create_agent_node(\"TriageMedicalAssessmentAgent\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:26:08.242402Z","iopub.execute_input":"2025-04-19T12:26:08.242761Z","iopub.status.idle":"2025-04-19T12:26:09.203068Z","shell.execute_reply.started":"2025-04-19T12:26:08.242731Z","shell.execute_reply":"2025-04-19T12:26:09.202126Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# ----------------------------------------\n# ğŸ§  SECTION 3: Phases 1â€“3 + Multi-Patient + Full Playback + PDF Export + OpenAI Key Fix\n# ----------------------------------------","metadata":{}},{"cell_type":"code","source":"pip install gTTS\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:26:09.203753Z","iopub.execute_input":"2025-04-19T12:26:09.204170Z","iopub.status.idle":"2025-04-19T12:26:13.121236Z","shell.execute_reply.started":"2025-04-19T12:26:09.204145Z","shell.execute_reply":"2025-04-19T12:26:13.119803Z"}},"outputs":[{"name":"stdout","text":"Collecting gTTS\n  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from gTTS) (2.32.3)\nRequirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.11/dist-packages (from gTTS) (8.1.8)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (2025.1.31)\nDownloading gTTS-2.5.4-py3-none-any.whl (29 kB)\nInstalling collected packages: gTTS\nSuccessfully installed gTTS-2.5.4\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import os\n\n# Make sure the sounds/ directory exists\nos.makedirs(\"sounds\", exist_ok=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:26:13.122671Z","iopub.execute_input":"2025-04-19T12:26:13.123066Z","iopub.status.idle":"2025-04-19T12:26:13.128297Z","shell.execute_reply.started":"2025-04-19T12:26:13.122997Z","shell.execute_reply":"2025-04-19T12:26:13.127424Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import os\nimport shutil\n\n# Step 1: Create the target directory if it doesn't exist\nos.makedirs(\"sounds\", exist_ok=True)\n\n# Step 2: Copy the ringtone from Kaggle input to working directory\nsource_path = \"/kaggle/input/ringtone/phone-ringtone-telephone-324474.mp3\"\ntarget_path = \"sounds/ringtone.mp3\"\n\n# Step 3: Copy the file\nshutil.copy(source_path, target_path)\n\nprint(f\"âœ… Ringtone copied to: {target_path}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:26:13.129254Z","iopub.execute_input":"2025-04-19T12:26:13.129582Z","iopub.status.idle":"2025-04-19T12:26:13.165597Z","shell.execute_reply.started":"2025-04-19T12:26:13.129554Z","shell.execute_reply":"2025-04-19T12:26:13.164781Z"}},"outputs":[{"name":"stdout","text":"âœ… Ringtone copied to: sounds/ringtone.mp3\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# ----------------------------------------\n# ğŸ§  ENHANCED SECTION 3: Phases 1â€“3 + Multi-Patient + Full Playback + PDF Export + OpenAI Key Fix\n# ----------------------------------------\n\nfrom pathlib import Path\nfrom pydub import AudioSegment\nfrom google.cloud import texttospeech\nfrom langgraph.graph import StateGraph\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\nfrom langchain.vectorstores import FAISS\nfrom langchain.document_loaders import TextLoader\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain.chains import RetrievalQA\nfrom reportlab.lib.pagesizes import letter\nfrom reportlab.pdfgen import canvas\nimport gradio as gr\nimport os, random, json, datetime\n\n# ----------------------------------------\n# ğŸ” Load OpenAI API Key from Kaggle Secrets\n# ----------------------------------------\n\ntry:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    os.environ[\"OPENAI_API_KEY\"] = user_secrets.get_secret(\"OPENAI_API_KEY\")\nexcept Exception as e:\n    print(\"âŒ Failed to load OPENAI_API_KEY:\", e)\n\n# ----------------------------------------\n# ğŸ‘¥ Multi-Patient Support\n# ----------------------------------------\n\ndef get_patient_by_name(name):\n    patients = {\n        \"anne\": {\n            \"name\": \"Anne\",\n            \"location\": \"Nice, France\",\n            \"symptoms\": \"severe leg pain after a fall\",\n            \"urgency\": \"emergency\"\n        },\n        \"liam\": {\n            \"name\": \"Liam\",\n            \"location\": \"Da Nang, Vietnam\",\n            \"symptoms\": \"high fever and dizziness\",\n            \"urgency\": \"outpatient\"\n        },\n        \"priya\": {\n            \"name\": \"Priya\",\n            \"location\": \"Doha Airport, Qatar\",\n            \"symptoms\": \"abdominal pain\",\n            \"urgency\": \"emergency\"\n        }\n    }\n    return patients.get(name.lower())\n\n# ----------------------------------------\n# ğŸ­ PHASE 1: Emotion presets\n# ----------------------------------------\n\nagent_emotions = {\n    \"ClientAgent\": \"stress\",\n    \"ClientAgent_2\": \"stress\",\n    \"ClientAgent_3\": \"concerned\",\n    \"ClientAgent_4\": \"curious\",\n    \"ClientAgent_5\": \"in_pain\",\n    \"ClientAgent_6\": \"grateful\",\n    \"ClientAgent\": \"stress\",\n    \"ClientInteractionAgent\": \"calm\",\n    \"TriageMedicalAssessmentAgent\": \"urgent\",\n    \"ProviderNetworkAgent\": \"neutral\",\n    \"PolicyValidationAgent\": \"neutral\",\n    \"MedicalDocumentationAgent\": \"calm\",\n    \"RepatriationPlannerAgent\": \"calm\",\n    \"MedicalDecisionAgent\": \"calm\",\n    \"ComplianceConsentAgent\": \"neutral\",\n    \"CountryCareLevelAgent\": \"neutral\",\n    \"OrchestratorAgent\": \"calm\"\n}\n\naudio_dir = Path(\"tts_audio\"); audio_dir.mkdir(exist_ok=True)\nlog_file = Path(\"case_log.txt\")\nzip_output = Path(\"case_export.zip\")\n\nambient_map = {\n    \"hospital\": \"ambient_hospital.mp3\",\n    \"airport\": \"ambient_airport.mp3\"\n}\n\ntry:\n    tts_client = texttospeech.TextToSpeechClient()\nexcept Exception as e:\n    print(\"âš ï¸ Google TTS setup failed:\", e)\n    tts_client = None\n\n# ----------------------------------------\n# ğŸ”ˆ SSML-based TTS with ğŸ“ Ringtone Support\n# ----------------------------------------\n\nfrom gtts import gTTS\nfrom pydub import AudioSegment\nimport io\n\n# Toggle between Google Cloud TTS and gTTS\nuse_google_tts = False\n\nfrom gtts import gTTS\nfrom pydub import AudioSegment\nimport io\n\n# Optional ringtone path (5s slice)\nringtone_path = Path(\"sounds/ringtone.mp3\")\nringtone = AudioSegment.from_file(ringtone_path)[:5000] if ringtone_path.exists() else AudioSegment.silent(duration=5000)\n\n# Voice presets\nclient_voices = {\n    \"liam\": \"en-GB-Standard-A\",   # âœ… Deep British male\n    \"anne\": \"en-GB-Wavenet-F\",    # Female\n    \"priya\": \"en-GB-Wavenet-F\"    # Female\n}\nagent_voice = \"en-GB-Wavenet-D\"  # Neutral/friendly female support voice\n\ndef synthesize_speech(text, agent, emotion=\"neutral\", context=\"none\"):\n    pitch = \"+2st\" if emotion == \"calm\" else \"-2st\"\n    rate = \"slow\" if emotion == \"stress\" else \"medium\"\n    if emotion == \"urgent\":\n        rate = \"fast\"\n        pitch = \"+0st\"\n\n    mp3_path = audio_dir / f\"{agent}_{random.randint(1000, 9999)}.mp3\"\n\n    # ğŸ“ Detect ringtone\n    has_ringtone = \"ğŸ“\" in text\n    clean_text = text.replace(\"ğŸ“\", \"\").strip()\n\n    # ğŸ‘¥ Determine speaker role\n    is_client = agent.startswith(\"ClientAgent\")\n\n    # ğŸ‘¥ Assign voice based on speaker role and content\n    if is_client:\n        if \"anne\" in clean_text.lower():\n            voice_name = \"en-GB-Wavenet-F\"\n        elif \"priya\" in clean_text.lower():\n            voice_name = \"en-GB-Wavenet-F\"\n        else:\n            voice_name = \"en-GB-Wavenet-B\"  # Male voice for Liam\n    else:\n        voice_name = \"en-GB-Wavenet-F\"  # Female voice for agents\n\n    print(f\"ğŸ¤ Using voice {voice_name} for agent '{agent}'\")\n\n    # Try to extract patient name from the sentence for dynamic mapping\n    for name in client_voices.keys():\n        if name.lower() in clean_text.lower():\n            patient_name = name.lower()\n            break\n\n    # ğŸ¤ Select voice\n    # Set patient name safely (fallback to 'liam' if not found)\n    patient_name = \"\"\n    if \"liam\" in clean_text.lower():\n        patient_name = \"liam\"\n    elif \"anne\" in clean_text.lower():\n        patient_name = \"anne\"\n    elif \"priya\" in clean_text.lower():\n        patient_name = \"priya\"\n    else:\n        patient_name = \"liam\"  # Default\n\n    # Choose voice\n    voice_name = client_voices.get(patient_name, \"en-GB-Wavenet-B\") if is_client else agent_voice\n\n    print(f\"ğŸ™ï¸ Speaker: {agent} â†’ Voice: {voice_name}\")\n\n    try:\n        if use_google_tts and tts_client:\n            # Google Cloud TTS\n            ssml = f\"\"\"\n            <speak>\n              <prosody rate=\"{rate}\" pitch=\"{pitch}\">\n                {clean_text}\n              </prosody>\n            </speak>\n            \"\"\"\n            input_text = texttospeech.SynthesisInput(ssml=ssml)\n            voice = texttospeech.VoiceSelectionParams(language_code=\"en-GB\", name=voice_name)\n            audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)\n\n            response = tts_client.synthesize_speech(input=input_text, voice=voice, audio_config=audio_config)\n            voice_audio = AudioSegment.from_file(io.BytesIO(response.audio_content), format=\"mp3\")\n\n        else:\n            # gTTS fallback\n            print(f\"ğŸ—£ï¸ Using gTTS fallback for {agent}\")\n            tts = gTTS(text=clean_text, lang=\"en\", slow=False)\n            temp_path = audio_dir / f\"temp_{agent}.mp3\"\n            tts.save(temp_path)\n            voice_audio = AudioSegment.from_file(temp_path)\n            temp_path.unlink()\n\n        # ğŸ”” Ringtone + pause\n        pause = AudioSegment.silent(duration=700)\n        final_audio = ringtone + pause + voice_audio if has_ringtone else voice_audio\n        final_audio.export(mp3_path, format=\"mp3\")\n        return str(mp3_path)\n\n    except Exception as e:\n        print(f\"âŒ TTS failed for {agent}: {e}\")\n        return generate_placeholder_audio(agent, clean_text)\n\n\ndef generate_placeholder_audio(agent, text=\"\"):\n    has_ringtone = \"ğŸ“\" in text\n    silent = AudioSegment.silent(duration=1000)\n    ring = ringtone[:5000] if has_ringtone else AudioSegment.silent(duration=0)\n    final_audio = ring + silent\n    path = audio_dir / f\"NO_AUDIO_{agent}.mp3\"\n    final_audio.export(path, format=\"mp3\")\n    return str(path)\n\n\n# ----------------------------------------\n# ğŸ§  PHASE 3: Mocked RAG Knowledge Bases\n# ----------------------------------------\n\nPath(\"rag_docs\").mkdir(exist_ok=True)\nPath(\"rag_docs/hospital_data.txt\").write_text(\n    \"Hospital Pasteur is a Level 1 trauma center in Nice, France. It includes ICU facilities and is in-network.\"\n)\nPath(\"rag_docs/policy_terms.txt\").write_text(\n    \"Standard policy covers outpatient and emergency treatment, includes repatriation with escort in emergencies.\"\n)\n\ndef create_rag_chain(file):\n    loader = TextLoader(file)\n    docs = loader.load()\n    chunks = CharacterTextSplitter(chunk_size=300, chunk_overlap=50).split_documents(docs)\n    vector = FAISS.from_documents(chunks, OpenAIEmbeddings())\n    return RetrievalQA.from_chain_type(llm=ChatOpenAI(temperature=0), retriever=vector.as_retriever())\n\nrag_hospital = create_rag_chain(\"rag_docs/hospital_data.txt\")\nrag_policy = create_rag_chain(\"rag_docs/policy_terms.txt\")\n\n# ----------------------------------------\n# ğŸ”— PHASE 2: LangGraph Agent Nodes (with schema + debugging)\n# ----------------------------------------\n\nfrom typing import TypedDict, List\nfrom langgraph.graph import StateGraph\n\n# âœ… 1. Define your state schema\nclass AgentState(TypedDict):\n    patient: dict\n    script: dict\n    log: List[str]\n    audio: List[str]\n\n# âœ… 2. Define each agent node function with debug\ndef agent_node(agent_name):\n    def run(state: AgentState) -> AgentState:\n        print(f\"ğŸš€ Executing {agent_name}...\")  # Debug: agent being run\n\n        emotion = agent_emotions.get(agent_name, \"neutral\")\n        context = \"hospital\" if \"Hospital\" in agent_name else \"airport\" if \"Repatriation\" in agent_name else \"none\"\n        msg = state[\"script\"].get(agent_name, f\"{agent_name} is processing...\")\n\n        if agent_name == \"ProviderNetworkAgent\":\n            print(\"ğŸ“¡ RAG query: hospital\")\n            msg = rag_hospital.run(\"What care level does Hospital Pasteur provide?\")\n        elif agent_name == \"PolicyValidationAgent\":\n            print(\"ğŸ“¡ RAG query: policy\")\n            msg = rag_policy.run(\"Is repatriation with escort covered?\")\n\n        state[\"log\"].append(f\"{agent_name}: {msg}\")\n        print(f\"ğŸ“ Log entry added for {agent_name}\")\n\n        audio = synthesize_speech(msg, agent=agent_name, emotion=emotion, context=context)\n        print(f\"ğŸ”Š Audio synthesized for {agent_name}: {audio}\")\n\n        state[\"audio\"].append(audio)\n        return state\n    return run\n\n# âœ… 3. Build the workflow graph using the schema\ndef build_workflow():\n    print(\"ğŸ› ï¸ Building LangGraph workflow...\")\n\n    graph = StateGraph(AgentState)\n\n    # â• Add all nodes\n    nodes = list(agent_emotions.keys())\n    for node in nodes:\n        print(f\"â• Adding node: {node}\")\n        graph.add_node(node, agent_node(node))\n\n    # ğŸ”— Add edges (INSERT YOUR EDGE LOGIC HERE)\n    graph.add_edge(\"ClientAgent\", \"ClientInteractionAgent\")\n    graph.add_edge(\"ClientInteractionAgent\", \"TriageMedicalAssessmentAgent\")\n    graph.add_edge(\"TriageMedicalAssessmentAgent\", \"ClientAgent_2\")\n    graph.add_edge(\"ClientAgent_2\", \"ProviderNetworkAgent\")\n    graph.add_edge(\"ProviderNetworkAgent\", \"ClientAgent_3\")\n    graph.add_edge(\"ClientAgent_3\", \"MedicalDocumentationAgent\")\n    graph.add_edge(\"MedicalDocumentationAgent\", \"ClientAgent_4\")\n    graph.add_edge(\"ClientAgent_4\", \"PolicyValidationAgent\")\n    graph.add_edge(\"PolicyValidationAgent\", \"MedicalDecisionAgent\")\n    graph.add_edge(\"MedicalDecisionAgent\", \"ClientAgent_5\")\n    graph.add_edge(\"ClientAgent_5\", \"RepatriationPlannerAgent\")\n    graph.add_edge(\"RepatriationPlannerAgent\", \"ComplianceConsentAgent\")\n    graph.add_edge(\"ComplianceConsentAgent\", \"ClientAgent_6\")\n    graph.add_edge(\"ClientAgent_6\", \"CountryCareLevelAgent\")\n    graph.add_edge(\"CountryCareLevelAgent\", \"OrchestratorAgent\")\n\n    # ğŸš€ Set entry/finish points\n    graph.set_entry_point(\"ClientAgent\")\n    graph.set_finish_point(\"OrchestratorAgent\")\n\n    compiled_graph = graph.compile()\n    print(\"âœ… LangGraph compiled successfully!\")\n    return compiled_graph\n    \n# ----------------------------------------\n# ğŸ§© Combine All Audio Clips\n# ----------------------------------------\n\ndef concatenate_audio(audio_paths, output_path):\n    combined = AudioSegment.empty()\n    for path in audio_paths:\n        combined += AudioSegment.from_file(path)\n    combined.export(output_path, format=\"mp3\")\n    return output_path\n\n# ----------------------------------------\n# ğŸ“ Generate PDF Conversation Log\n# ----------------------------------------\n\ndef generate_pdf_from_log(log_lines, pdf_path):\n    c = canvas.Canvas(str(pdf_path), pagesize=letter)\n    width, height = letter\n    c.setFont(\"Helvetica\", 10)\n    c.drawString(30, height - 40, f\"Conversation Log - Generated: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n    y = height - 60\n    for line in log_lines:\n        if y < 40:\n            c.showPage(); c.setFont(\"Helvetica\", 10); y = height - 40\n        c.drawString(30, y, line)\n        y -= 14\n    c.save()\n\n# ----------------------------------------\n# â–¶ï¸ Run Simulation for Any Patient\n# ----------------------------------------\n\n# ğŸ’¬ Patient-specific scripts\npatient_scripts = {\n    \"Liam\": {\n        \"ClientAgent\": \"ğŸ“ Hello? Iâ€™m Liam, I fell while hiking in Da Nang and my leg really hurts. I can't walk.\",\n        \"ClientInteractionAgent\": \"Hi Liam. Are you alone? Do you have insurance details and your location?\",\n        \"TriageMedicalAssessmentAgent\": \"This is an emergency. Dispatching ambulance. Donâ€™t move.\",\n        \"ClientAgent_2\": \"ğŸ“ Ambulance took me to a clinic. Iâ€™m not sure itâ€™s safe. Can you advise?\",\n        \"ProviderNetworkAgent\": \"Please go to Hospital Pasteur. Itâ€™s in our network and has English-speaking doctors.\",\n        \"ClientAgent_3\": \"ğŸ“ Iâ€™m here. Can you contact the doctor? I need advice.\",\n        \"MedicalDocumentationAgent\": \"Weâ€™ll request your medical report and Fit-to-Fly if youâ€™re discharged.\",\n        \"ClientAgent_4\": \"ğŸ“ Can my partner travel with me back home?\",\n        \"PolicyValidationAgent\": \"If they are listed, yes. Repatriation is covered for you.\",\n        \"MedicalDecisionAgent\": \"The injury is stable. Youâ€™re getting proper care.\",\n        \"ClientAgent_5\": \"ğŸ“ Discharged but still in pain. I need support to fly.\",\n        \"RepatriationPlannerAgent\": \"Weâ€™ll arrange wheelchair assistance and extra seat for your leg.\",\n        \"ComplianceConsentAgent\": \"Do you consent to share your medical data for travel planning?\",\n        \"ClientAgent_6\": \"ğŸ“ Yes, I consent.\",\n        \"CountryCareLevelAgent\": \"Vietnam is Level 2. No escalation needed.\",\n        \"OrchestratorAgent\": \"Case closed for Liam. Logs and KPIs updated.\"\n    },\n    \"Anne\": {\n        \"ClientAgent\": \"ğŸ“ Hi, this is Anne. I slipped at my hotel in Rome. I think I fractured my arm.\",\n        \"ClientInteractionAgent\": \"Hi Anne. Iâ€™m here to help. Can you describe your symptoms and location?\",\n        \"TriageMedicalAssessmentAgent\": \"This may require an ER visit. Letâ€™s send a doctor.\",\n        \"ClientAgent_2\": \"ğŸ“ I'm at the clinic but unsure if itâ€™s reliable.\",\n        \"ProviderNetworkAgent\": \"Go to Policlinico Umberto I. Itâ€™s trusted and has English-speaking staff.\",\n        \"ClientAgent_3\": \"ğŸ“ Doctor saw me. Can you request the documents?\",\n        \"MedicalDocumentationAgent\": \"Getting discharge report and invoice. Requesting Fit-to-Fly if needed.\",\n        \"ClientAgent_4\": \"ğŸ“ Whatâ€™s covered under my policy?\",\n        \"PolicyValidationAgent\": \"Treatment is covered. Repatriation too if youâ€™re unable to travel alone.\",\n        \"MedicalDecisionAgent\": \"Fracture confirmed. Non-surgical. Safe for return with escort.\",\n        \"ClientAgent_5\": \"ğŸ“ Iâ€™m in a sling. Itâ€™s hard to carry luggage.\",\n        \"RepatriationPlannerAgent\": \"Weâ€™ll arrange a nurse escort and assistance throughout the journey.\",\n        \"ComplianceConsentAgent\": \"Do you consent to share reports with airline and our team?\",\n        \"ClientAgent_6\": \"ğŸ“ Yes, I consent.\",\n        \"CountryCareLevelAgent\": \"Italy is Level 1. Standard follow-up applies.\",\n        \"OrchestratorAgent\": \"Case closed for Anne. Everything logged.\"\n    },\n    \"Priya\": {\n        \"ClientAgent\": \"ğŸ“ Hello, Iâ€™m Priya. Iâ€™ve had food poisoning in Bangkok and feel very weak.\",\n        \"ClientInteractionAgent\": \"Hi Priya. Iâ€™m sorry to hear that. Letâ€™s get your location and insurance ID.\",\n        \"TriageMedicalAssessmentAgent\": \"This might be outpatient. Weâ€™ll send a doctor to your hotel.\",\n        \"ClientAgent_2\": \"ğŸ“ The doctor came but now Iâ€™m worse.\",\n        \"ProviderNetworkAgent\": \"Switch to Bumrungrad Hospital â€“ top-rated with translators on staff.\",\n        \"ClientAgent_3\": \"ğŸ“ Iâ€™m at the ER now. Whatâ€™s next?\",\n        \"MedicalDocumentationAgent\": \"Weâ€™re retrieving your reports and confirming Fit-to-Fly readiness.\",\n        \"ClientAgent_4\": \"ğŸ“ Iâ€™m flying soon. Will this affect my coverage?\",\n        \"PolicyValidationAgent\": \"Yes, but outpatient care is covered. Flight may need rebooking.\",\n        \"MedicalDecisionAgent\": \"Symptoms under control. OK to fly with precautions.\",\n        \"ClientAgent_5\": \"ğŸ“ Still feeling dizzy.\",\n        \"RepatriationPlannerAgent\": \"Weâ€™ll book a business class seat and ground escort to the airport.\",\n        \"ComplianceConsentAgent\": \"Do we have your consent to proceed?\",\n        \"ClientAgent_6\": \"ğŸ“ Yes, go ahead.\",\n        \"CountryCareLevelAgent\": \"Thailand is Level 2. Monitoring continues.\",\n        \"OrchestratorAgent\": \"Priyaâ€™s case wrapped up. Logs completed.\"\n    }\n}\n\n\ndef run_simulation_ui(patient_name):\n    patient = get_patient_by_name(patient_name)\n    if not patient:\n        return \"âŒ Patient not found.\", None, None\n\n    # ğŸ§  Select patient-specific script\n    script = patient_scripts.get(patient_name.lower().capitalize())\n    if not script:\n        return \"âŒ No conversation script found for this patient.\", None, None\n\n    # ğŸ§¹ Cleanup previous logs/audio\n    if log_file.exists():\n        log_file.unlink()\n    for f in audio_dir.glob(\"*.mp3\"):\n        f.unlink()\n\n    # ğŸš€ Run workflow\n    graph = build_workflow()\n    state = graph.invoke({\n        \"patient\": patient,\n        \"script\": script,\n        \"log\": [],\n        \"audio\": []\n    })\n\n    # ğŸ§ Output paths\n    full_audio_path = audio_dir / f\"{patient_name}_full_convo.mp3\"\n    pdf_path = audio_dir / f\"{patient_name}_conversation.pdf\"\n\n    concatenate_audio(state[\"audio\"], full_audio_path)\n    generate_pdf_from_log(state[\"log\"], pdf_path)\n\n    # ğŸ“¦ Export ZIP\n    with zip_output.open(\"wb\") as f:\n        from zipfile import ZipFile\n        with ZipFile(f, \"w\") as zipf:\n            for a in state[\"audio\"]:\n                zipf.write(a, arcname=os.path.basename(a))\n            with open(log_file, \"w\") as lf:\n                lf.write(\"\\n\".join(state[\"log\"]))\n            zipf.write(log_file, arcname=log_file.name)\n            zipf.write(pdf_path, arcname=pdf_path.name)\n            zipf.write(full_audio_path, arcname=full_audio_path.name)\n\n    return \"\\n\".join(state[\"log\"]), str(zip_output), str(full_audio_path)\n\n# ----------------------------------------\n# ğŸ›ï¸ Gradio UI with Full Playback + PDF Export\n# ----------------------------------------\n\ndef launch_ui():\n    gr.Interface(\n        fn=run_simulation_ui,\n        inputs=gr.Dropdown(choices=[\"Anne\", \"Liam\", \"Priya\"], label=\"Select Patient\"),\n        outputs=[\n            gr.Textbox(label=\"Conversation Log\"),\n            gr.File(label=\"Download ZIP (Logs + Audio + PDF)\"),\n            gr.Audio(label=\"Listen to Full Conversation\", type=\"filepath\", show_download_button=True)\n        ],\n        title=\"ğŸ§  Global MedAssist â€“ Full Playback + PDF\",\n        description=\"Multi-agent simulation with SSML tone, LangGraph, RAG, and PDF export\"\n    ).launch(share=True)\n\n# ğŸ”¥ Launch it\nlaunch_ui()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:26:13.167144Z","iopub.execute_input":"2025-04-19T12:26:13.167530Z","iopub.status.idle":"2025-04-19T12:26:36.448721Z","shell.execute_reply.started":"2025-04-19T12:26:13.167491Z","shell.execute_reply":"2025-04-19T12:26:36.447625Z"}},"outputs":[{"name":"stdout","text":"* Running on local URL:  http://127.0.0.1:7860\n* Running on public URL: https://bff754bb1cd92b7d64.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://bff754bb1cd92b7d64.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"## SECTION 4: Unit Test & Debugging Code:","metadata":{}},{"cell_type":"code","source":"import unittest\nimport os\nimport json\nfrom pathlib import Path\nfrom datetime import datetime\nfrom geopy.distance import distance\n\n# Define the functions being tested\n\ndef generate_case_number():\n    return f\"GB1-{random.randint(100, 999)}-{random.randint(100, 999)}\"\n\ndef save_case(case_data):\n    case_number = case_data[\"case_number\"]\n    with open(f\"case_files/{case_number}.json\", \"w\") as f:\n        json.dump(case_data, f, indent=4)\n\ndef extract_coordinates_from_text(text):\n    coords = re.findall(r\"(-?\\d+\\.\\d+),\\s*(-?\\d+\\.\\d+)\", text)\n    if coords:\n        return float(coords[0][0]), float(coords[0][1])\n    return None\n\ndef find_closest_hospital(user_coords):\n    min_dist = float(\"inf\")\n    closest = None\n    for name, coords in hospital_locations.items():\n        dist_km = distance(user_coords, coords).km\n        if dist_km < min_dist:\n            min_dist = dist_km\n            closest = (name, coords, dist_km)\n    return closest\n\n# Test cases\n\nclass TestMedicalAssistantFunctions(unittest.TestCase):\n\n    def test_generate_case_number(self):\n        # Test case number generation\n        case_number = generate_case_number()\n        self.assertTrue(case_number.startswith(\"GB1-\"))\n        self.assertEqual(len(case_number.split('-')[1]), 3)  # Checks the length of the first random part\n        self.assertEqual(len(case_number.split('-')[2]), 3)  # Checks the length of the second random part\n\n    def test_save_case(self):\n        # Test saving case data to file\n        case_data = {\n            \"case_number\": \"GB1-123-456\",\n            \"full_name\": \"John Doe\",\n            \"home_address\": \"123 Main St\",\n            \"outbound_flight\": \"2025-04-01\",\n            \"return_flight\": \"2025-04-10\",\n            \"created_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n            \"chat_history\": []\n        }\n        save_case(case_data)  # Saving case\n        self.assertTrue(Path(f\"case_files/{case_data['case_number']}.json\").exists())  # Check if file is saved\n\n    def test_extract_coordinates_from_text(self):\n        # Test extracting coordinates from a string\n        text = \"The hospital is located at 13.7489, 100.5562.\"\n        coords = extract_coordinates_from_text(text)\n        self.assertEqual(coords, (13.7489, 100.5562))  # Test if the extracted coordinates match\n\n    def test_find_closest_hospital(self):\n        # Test finding the closest hospital\n        coords = (13.7489, 100.5562)\n        closest_hospital = find_closest_hospital(coords)\n        self.assertTrue(closest_hospital[2] < 100)  # Check if the distance is below a certain threshold\n\n# Run tests\ndef run_tests():\n    # Initialize test suite\n    suite = unittest.TestLoader().loadTestsFromTestCase(TestMedicalAssistantFunctions)\n    unittest.TextTestRunner().run(suite)\n\nrun_tests()\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:26:36.449853Z","iopub.execute_input":"2025-04-19T12:26:36.450205Z","iopub.status.idle":"2025-04-19T12:26:36.886608Z","shell.execute_reply.started":"2025-04-19T12:26:36.450178Z","shell.execute_reply":"2025-04-19T12:26:36.885733Z"}},"outputs":[{"name":"stderr","text":"EE.E\n======================================================================\nERROR: test_extract_coordinates_from_text (__main__.TestMedicalAssistantFunctions.test_extract_coordinates_from_text)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/tmp/ipykernel_31/202697182.py\", line 62, in test_extract_coordinates_from_text\n    coords = extract_coordinates_from_text(text)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_31/202697182.py\", line 19, in extract_coordinates_from_text\n    coords = re.findall(r\"(-?\\d+\\.\\d+),\\s*(-?\\d+\\.\\d+)\", text)\n             ^^\nNameError: name 're' is not defined\n\n======================================================================\nERROR: test_find_closest_hospital (__main__.TestMedicalAssistantFunctions.test_find_closest_hospital)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/tmp/ipykernel_31/202697182.py\", line 68, in test_find_closest_hospital\n    closest_hospital = find_closest_hospital(coords)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_31/202697182.py\", line 27, in find_closest_hospital\n    for name, coords in hospital_locations.items():\n                        ^^^^^^^^^^^^^^^^^^\nNameError: name 'hospital_locations' is not defined\n\n======================================================================\nERROR: test_save_case (__main__.TestMedicalAssistantFunctions.test_save_case)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/tmp/ipykernel_31/202697182.py\", line 56, in test_save_case\n    save_case(case_data)  # Saving case\n    ^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_31/202697182.py\", line 15, in save_case\n    with open(f\"case_files/{case_number}.json\", \"w\") as f:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: 'case_files/GB1-123-456.json'\n\n----------------------------------------------------------------------\nRan 4 tests in 0.005s\n\nFAILED (errors=3)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# SECTION 5: Travel Assistance Chat bot","metadata":{}},{"cell_type":"code","source":"!pip install folium --quiet\n!pip install transformers torchvision torch --quiet\n!pip install python-docx fpdf --quiet\n!pip install gradio --quiet\n!pip install fitz --quiet\n!pip install tools --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:26:36.889628Z","iopub.execute_input":"2025-04-19T12:26:36.890233Z","iopub.status.idle":"2025-04-19T12:28:40.661943Z","shell.execute_reply.started":"2025-04-19T12:26:36.890208Z","shell.execute_reply":"2025-04-19T12:28:40.660273Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m95.4/95.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m421.5/421.5 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m528.1/528.1 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m101.4/101.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for tools (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for pytils (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# SECTION 5.1. Generating Medical Reports","metadata":{}},{"cell_type":"code","source":"from docx import Document\nfrom fpdf import FPDF\nimport os\nimport json\n\n# Directory to store fake reports on Kaggle\noutput_dir = \"/kaggle/working/medical_reports\"\nos.makedirs(output_dir, exist_ok=True)\n\n# Detailed fake medical reports\ndetailed_medical_reports = {\n    \"Liam\": {\n        \"patient_name\": \"Liam Thompson\",\n        \"dob\": \"1990-07-15\",\n        \"admission_date\": \"2025-04-13\",\n        \"discharge_date\": \"2025-04-17\",\n        \"incident_description\": \"Patient slipped while hiking in Da Nang, landed on his right leg with a twisting force.\",\n        \"vitals_on_admission\": {\n            \"BP\": \"135/85 mmHg\",\n            \"HR\": \"88 bpm\",\n            \"Temp\": \"37.2Â°C\",\n            \"RR\": \"18 breaths/min\",\n            \"SpO2\": \"98% on room air\"\n        },\n        \"diagnosis\": \"Closed displaced comminuted fracture of the mid-shaft of the right tibia.\",\n        \"tests\": {\n            \"X-ray\": \"Fracture confirmed with slight displacement, no fibular involvement.\",\n            \"CBC\": \"WBC: 8.2 x10^9/L, Hb: 14.5 g/dL, Platelets: 210 x10^9/L\",\n            \"CRP\": \"Normal\"\n        },\n        \"treatment\": \"Leg immobilized with fiberglass cast under sedation. Analgesics administered: IV Paracetamol and Morphine. Antibiotic prophylaxis given. Scheduled physiotherapy initiated.\",\n        \"medications_received\": [\n            \"IV Paracetamol 1g q8h\",\n            \"IV Morphine 2mg PRN\",\n            \"IV Ceftriaxone 1g once (prophylaxis)\"\n        ],\n        \"medical_evolution\": \"Stable vitals throughout admission. Pain managed effectively. Ambulation with walker initiated on Day 3.\",\n        \"surgical_procedures\": \"None performed. Orthopedic review confirmed non-surgical management appropriate.\",\n        \"discharge_medications\": [\n            \"Paracetamol 500mg PO q6h PRN\",\n            \"Ibuprofen 400mg PO TID\"\n        ],\n        \"equipment_on_discharge\": \"Full-length leg cast with instructions for non-weight bearing.\",\n        \"fit_to_fly\": \"Yes, with wheelchair assistance and extra legroom.\",\n        \"prognosis\": \"Favorable recovery expected within 6â€“8 weeks.\",\n        \"recommendation\": \"Repatriation with commercial flight, nurse escort not necessary.\",\n        \"discharge_plan\": \"Follow-up in orthopedic clinic in home country in 7 days. Continue analgesics and physiotherapy exercises.\"\n    },\n    \"Anne\": {\n        \"patient_name\": \"Anne Dupont\",\n        \"dob\": \"1987-11-23\",\n        \"admission_date\": \"2025-04-10\",\n        \"discharge_date\": \"2025-04-12\",\n        \"incident_description\": \"Slipped on wet bathroom floor in hotel, landed on outstretched left hand.\",\n        \"vitals_on_admission\": {\n            \"BP\": \"120/80 mmHg\",\n            \"HR\": \"75 bpm\",\n            \"Temp\": \"36.8Â°C\",\n            \"RR\": \"16 breaths/min\",\n            \"SpO2\": \"99%\"\n        },\n        \"diagnosis\": \"Non-displaced hairline fracture of the distal left radius.\",\n        \"tests\": {\n            \"X-ray\": \"Confirmed distal radial fracture with no displacement or angulation.\",\n            \"CBC\": \"Normal\",\n            \"Electrolytes\": \"Normal\"\n        },\n        \"treatment\": \"Arm placed in a padded sling. No reduction required. Pain managed conservatively.\",\n        \"medications_received\": [\n            \"Oral Ibuprofen 400mg TID\",\n            \"Oral Paracetamol 500mg PRN\"\n        ],\n        \"medical_evolution\": \"No swelling progression. Pain reduced after 48h. No complications.\",\n        \"surgical_procedures\": \"Not indicated.\",\n        \"discharge_medications\": [\n            \"Paracetamol 500mg PO q6h PRN\"\n        ],\n        \"equipment_on_discharge\": \"Sling to immobilize left arm.\",\n        \"fit_to_fly\": \"Yes, sling use and baggage assistance required.\",\n        \"prognosis\": \"Expected full recovery in 4â€“5 weeks with outpatient follow-up.\",\n        \"recommendation\": \"Repatriation with nurse escort to assist with mobility and baggage.\",\n        \"discharge_plan\": \"Orthopedic follow-up in 10 days. Avoid weight bearing with left hand.\"\n    },\n    \"Priya\": {\n        \"patient_name\": \"Priya Mehta\",\n        \"dob\": \"1995-02-02\",\n        \"admission_date\": \"2025-04-09\",\n        \"discharge_date\": \"2025-04-11\",\n        \"incident_description\": \"Consumed seafood at local night market in Bangkok, followed by vomiting and diarrhea.\",\n        \"vitals_on_admission\": {\n            \"BP\": \"100/65 mmHg\",\n            \"HR\": \"105 bpm\",\n            \"Temp\": \"38.1Â°C\",\n            \"RR\": \"20 breaths/min\",\n            \"SpO2\": \"98%\"\n        },\n        \"diagnosis\": \"Acute gastroenteritis with moderate dehydration.\",\n        \"tests\": {\n            \"Stool culture\": \"Pending\",\n            \"CBC\": \"WBC: 12.3 x10^9/L, Hb: 13.0 g/dL\",\n            \"Electrolytes\": \"Na: 130 mmol/L, K: 3.2 mmol/L\"\n        },\n        \"treatment\": \"Admitted for IV fluid replacement. Antiemetics and broad-spectrum antibiotics administered.\",\n        \"medications_received\": [\n            \"IV Ringerâ€™s Lactate\",\n            \"Ondansetron 4mg IV\",\n            \"Oral Ciprofloxacin 500mg BID x3 days\"\n        ],\n        \"medical_evolution\": \"Improved hydration, no further vomiting after Day 1. Oral intake resumed.\",\n        \"surgical_procedures\": \"None.\",\n        \"discharge_medications\": [\n            \"Oral Rehydration Salts\",\n            \"Ciprofloxacin 500mg BID (complete 3-day course)\"\n        ],\n        \"equipment_on_discharge\": \"None required.\",\n        \"fit_to_fly\": \"Yes, after 48-hour monitoring and electrolyte correction.\",\n        \"prognosis\": \"Full recovery expected in 2â€“3 days.\",\n        \"recommendation\": \"Repatriation by commercial flight, no escort required.\",\n        \"discharge_plan\": \"Continue oral hydration and antibiotics. Follow-up only if symptoms return.\"\n    }\n}\n\n# Save JSON for app use\njson_path = os.path.join(output_dir, \"summary_reports.json\")\nwith open(json_path, \"w\") as f:\n    json.dump(detailed_medical_reports, f, indent=4)\n\n# Sanitizer for special characters\ndef sanitize_text(text):\n    if isinstance(text, str):\n        return (\n            text.replace(\"â€“\", \"-\")\n                .replace(\"â€”\", \"-\")\n                .replace(\"â€™\", \"'\")\n                .replace(\"â€˜\", \"'\")\n                .replace(\"â€œ\", '\"')\n                .replace(\"â€\", '\"')\n                .encode(\"latin-1\", \"ignore\").decode(\"latin-1\")\n        )\n    return str(text)\n\n# Generate both PDF and DOCX\ndef generate_reports():\n    paths = []\n    for person, data in detailed_medical_reports.items():\n        # PDF\n        pdf = FPDF()\n        pdf.add_page()\n        pdf.set_font(\"Arial\", size=12)\n        for key, value in data.items():\n            if isinstance(value, dict):\n                pdf.cell(200, 10, txt=sanitize_text(f\"{key.replace('_', ' ').title()}: \"), ln=True)\n                for sub_key, sub_val in value.items():\n                    pdf.cell(200, 10, txt=sanitize_text(f\"  {sub_key}: {sub_val}\"), ln=True)\n            elif isinstance(value, list):\n                pdf.cell(200, 10, txt=sanitize_text(f\"{key.replace('_', ' ').title()}: \"), ln=True)\n                for item in value:\n                    pdf.cell(200, 10, txt=sanitize_text(f\"  - {item}\"), ln=True)\n            else:\n                pdf.cell(200, 10, txt=sanitize_text(f\"{key.replace('_', ' ').title()}: {value}\"), ln=True)\n        pdf_path = os.path.join(output_dir, f\"{person}_report.pdf\")\n        pdf.output(pdf_path)\n        paths.append(pdf_path)\n\n        # DOCX\n        doc = Document()\n        doc.add_heading(f\"Medical Report - {person}\", 0)\n        for key, value in data.items():\n            if isinstance(value, dict):\n                doc.add_heading(key.replace('_', ' ').title(), level=2)\n                for sub_key, sub_val in value.items():\n                    doc.add_paragraph(f\"{sub_key}: {sub_val}\")\n            elif isinstance(value, list):\n                doc.add_heading(key.replace('_', ' ').title(), level=2)\n                for item in value:\n                    doc.add_paragraph(f\"- {item}\")\n            else:\n                doc.add_paragraph(f\"{key.replace('_', ' ').title()}: {value}\")\n        docx_path = os.path.join(output_dir, f\"{person}_report.docx\")\n        doc.save(docx_path)\n        paths.append(docx_path)\n\n    return paths\n\n# Run report generation\nreport_paths = generate_reports()\nreport_paths\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:28:40.664559Z","iopub.execute_input":"2025-04-19T12:28:40.664943Z","iopub.status.idle":"2025-04-19T12:28:40.993155Z","shell.execute_reply.started":"2025-04-19T12:28:40.664909Z","shell.execute_reply":"2025-04-19T12:28:40.992149Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"['/kaggle/working/medical_reports/Liam_report.pdf',\n '/kaggle/working/medical_reports/Liam_report.docx',\n '/kaggle/working/medical_reports/Anne_report.pdf',\n '/kaggle/working/medical_reports/Anne_report.docx',\n '/kaggle/working/medical_reports/Priya_report.pdf',\n '/kaggle/working/medical_reports/Priya_report.docx']"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"# SECTION 5.2. Refactoring Section: Synchronizing Agents with the LLM\n\nThis section introduces the necessary changes to synchronize all agents with the LLM (OpenAI GPT-4) for medical case management. It includes a utility function for querying the LLM, modified agent functions to communicate with the LLM, and orchestration logic to handle data flow between agents.","metadata":{}},{"cell_type":"markdown","source":"The query_llm function centralizes LLM communication, making it easier for agents to query the LLM without repeating code.\n\nEach agent now passes its data to the LLM to receive contextually relevant responses.\n\nThe OrchestratorAgent ensures that the workflow between agents is synchronized and maintains a unified chat history across the entire case management process.\n\nThis refactoring ensures that all agents interact with the LLM during their tasks. Each agent queries the LLM with relevant data, which ensures synchronized decision-making, empathetic responses, and a streamlined case management process.","metadata":{}},{"cell_type":"code","source":"# Utility function to handle communication with the LLM\ndef query_llm(agent_name, input_data, chat_history=[]):\n    \"\"\"\n    Sends a query to the LLM (OpenAI GPT-4) and returns the response.\n\n    Args:\n    - agent_name (str): The name of the agent requesting the information.\n    - input_data (str): The data or query to send to the LLM.\n    - chat_history (list): The conversation history to maintain context.\n\n    Returns:\n    - str: The LLM-generated response.\n    \"\"\"\n    # Prepares the system message (guiding the agent's behavior)\n    system_prompt = {\n        \"role\": \"system\",\n        \"content\": f\"You are the {agent_name}, an AI agent in a travel health insurance system. Provide thoughtful, empathetic, and accurate responses.\"\n    }\n\n    # Structure the LLM prompt based on the agent's task\n    user_prompt = {\n        \"role\": \"user\",\n        \"content\": input_data\n    }\n\n    # Complete messages list\n    messages = [system_prompt] + chat_history + [user_prompt]\n\n    # Query the OpenAI LLM\n    response = client.chat.completions.create(\n        model=\"gpt-4-turbo\",\n        messages=messages,\n        max_tokens=700\n    )\n\n    # Extract and return the LLM's response\n    return response.choices[0].message.content\n\n\n# Modify the agents to communicate with LLM\n\n# Client Interaction Agent\ndef ClientInteractionAgent(client_data, chat_history=[]):\n    input_data = f\"Client details: Name: {client_data['full_name']}, Policy ID: {client_data['policy_id']}, Incident: {client_data['incident_details']}. What should be the next step?\"\n    response = query_llm(\"ClientInteractionAgent\", input_data, chat_history)\n    return response\n\n\n# Triage Medical Assessment Agent\ndef TriageMedicalAssessmentAgent(symptoms, chat_history=[]):\n    input_data = f\"Symptoms reported: {symptoms}. Based on these, classify the case's urgency (outpatient, ER, inpatient).\"\n    response = query_llm(\"TriageMedicalAssessmentAgent\", input_data, chat_history)\n    return response\n\n\n# Provider Network Agent\ndef ProviderNetworkAgent(location, medical_needs, chat_history=[]):\n    input_data = f\"Find nearby medical providers for location: {location} and needs: {medical_needs}. Provide a list of suitable hospitals.\"\n    response = query_llm(\"ProviderNetworkAgent\", input_data, chat_history)\n    return response\n\n\n# Medical Documentation Agent\ndef MedicalDocumentationAgent(document_data, chat_history=[]):\n    input_data = f\"Process the medical document: {document_data}. Summarize the key details for policy validation.\"\n    response = query_llm(\"MedicalDocumentationAgent\", input_data, chat_history)\n    return response\n\n\n# Policy Validation Agent\ndef PolicyValidationAgent(policy_data, treatment_details, chat_history=[]):\n    input_data = f\"Validate the policy coverage for the treatment: {treatment_details}. Check for exclusions or co-pays in policy: {policy_data}.\"\n    response = query_llm(\"PolicyValidationAgent\", input_data, chat_history)\n    return response\n\n\n# Medical Decision Agent\ndef MedicalDecisionAgent(medical_data, chat_history=[]):\n    input_data = f\"Analyze the medical case: {medical_data}. Provide a decision on the recommended treatment options.\"\n    response = query_llm(\"MedicalDecisionAgent\", input_data, chat_history)\n    return response\n\n\n# Compliance Consent Agent\ndef ComplianceConsentAgent(consent_data, chat_history=[]):\n    input_data = f\"Ensure that the client has accepted the data-sharing terms. Validate their consent for medical treatment in compliance with legal regulations.\"\n    response = query_llm(\"ComplianceConsentAgent\", input_data, chat_history)\n    return response\n\n\n# Country Care Level Agent\ndef CountryCareLevelAgent(country, chat_history=[]):\n    input_data = f\"Determine the risk level of the country: {country}. Trigger escalation if the client is in a Level 3 country.\"\n    response = query_llm(\"CountryCareLevelAgent\", input_data, chat_history)\n    return response\n\n\n# Repatriation Planner Agent\ndef RepatriationPlannerAgent(transport_needs, chat_history=[]):\n    input_data = f\"Plan the repatriation for the client. Assess the feasibility of commercial flights, air ambulances, or ground transport.\"\n    response = query_llm(\"RepatriationPlannerAgent\", input_data, chat_history)\n    return response\n\n\n# Orchestrator Agent to manage data flow between agents\ndef OrchestratorAgent(case_data, chat_history=[]):\n    \"\"\"\n    Manages the flow of case data between the agents and keeps the conversation history intact.\n    \"\"\"\n    for agent_name, agent_data in case_data.items():\n        # Call the corresponding agent with the relevant data\n        response = globals()[f\"{agent_name}\"](agent_data, chat_history)\n        \n        # Add the response to chat history for context\n        chat_history.append({\"role\": \"assistant\", \"content\": response})\n    \n    # Return the final chat history for the entire process\n    return chat_history\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T13:22:41.969874Z","iopub.execute_input":"2025-04-19T13:22:41.970225Z","iopub.status.idle":"2025-04-19T13:22:41.984533Z","shell.execute_reply.started":"2025-04-19T13:22:41.970200Z","shell.execute_reply":"2025-04-19T13:22:41.983230Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"# SECTION 5.3. Imports and Global Setup for Medical Case Management","metadata":{}},{"cell_type":"code","source":"pip install PyMuPDF --quite\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:28:40.994462Z","iopub.execute_input":"2025-04-19T12:28:40.996106Z","iopub.status.idle":"2025-04-19T12:28:41.692652Z","shell.execute_reply.started":"2025-04-19T12:28:40.996074Z","shell.execute_reply":"2025-04-19T12:28:41.691288Z"}},"outputs":[{"name":"stdout","text":"\nUsage:   \n  /usr/bin/python3 -m pip install [options] <requirement specifier> [package-index-options] ...\n  /usr/bin/python3 -m pip install [options] -r <requirements file> [package-index-options] ...\n  /usr/bin/python3 -m pip install [options] [-e] <vcs project url> ...\n  /usr/bin/python3 -m pip install [options] [-e] <local project path> ...\n  /usr/bin/python3 -m pip install [options] <archive url/path> ...\n\nno such option: --quite\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import gradio as gr\nfrom openai import OpenAI\nfrom PIL import Image\nimport base64\nimport os\nimport folium\nimport re\nimport tempfile\nfrom geopy.distance import distance\nfrom transformers import BlipProcessor, BlipForConditionalGeneration\nimport torch\nimport fitz  # PyMuPDF for reading PDFs\nfrom docx import Document  # For Word documents\nimport json\nfrom datetime import datetime\nimport random\n\n\nclient = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n\n# Load Hugging Face model for image captioning\nprocessor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\nmodel = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n\n# ğŸŒ Country Levels\nlevel_1 = [\"United States\", \"Canada\", \"United Kingdom\", \"Germany\", \"France\", \"Japan\", \"Australia\", \"New Zealand\", \"Sweden\", \"Norway\", \"Netherlands\", \"Switzerland\", \"Italy\", \"Spain\", \"South Korea\", \"Singapore\"]\nlevel_2 = [\"Mexico\", \"Brazil\", \"Thailand\", \"Vietnam\", \"Turkey\", \"Malaysia\", \"Costa Rica\", \"Serbia\", \"India\", \"Philippines\", \"China\", \"Chile\", \"South Africa\", \"Indonesia\", \"Egypt\", \"UAE\"]\nlevel_3 = [\"Nepal\", \"Kenya\", \"Nigeria\", \"Pakistan\", \"Bangladesh\", \"Ethiopia\", \"Uganda\", \"Myanmar\", \"Cameroon\", \"Burkina Faso\", \"Zimbabwe\", \"DR Congo\", \"Sudan\", \"Ghana\", \"Bolivia\"]\n\n# ğŸ¥ Trusted Hospitals with coordinates\nhospital_locations = {\n    # Level 2 countries\n    \"Bumrungrad International Hospital\": (13.7489, 100.5562),\n    \"Samitivej Hospital\": (13.7300, 100.5684),\n    \"Hospital Pasteur\": (16.0471, 108.2062),\n    \"Franco-Vietnamese Hospital\": (10.7380, 106.7048),\n    \"Apollo Hospital\": (12.9438, 77.5858),\n    \"Fortis Hospital\": (28.4595, 77.0266),\n    \"Albert Einstein Hospital\": (-23.6090, -46.6946),\n    \"SÃ­rio-LibanÃªs Hospital\": (-23.5560, -46.6537),\n    \"Ãngeles Hospital\": (19.4326, -99.1332),\n    \"San Javier Hospital\": (20.6736, -103.3442),\n    \"As-Salam International Hospital\": (30.0444, 31.2357),\n    \"Cleopatra Hospital\": (30.0571, 31.3199),\n    \"Siloam Hospitals\": (-6.2088, 106.8456),\n    \"RSUP Dr. Sardjito\": (-7.7684, 110.3786),\n    \"Aga Khan University Hospital\": (-1.2921, 36.8219),\n    \"Nairobi Hospital\": (-1.3000, 36.8000),\n    \"Lagoon Hospital\": (6.5244, 3.3792),\n    \"Reddington Hospital\": (6.4396, 3.4216),\n    \"Cleveland Clinic Abu Dhabi\": (24.4539, 54.3773),\n    \"Mediclinic City Hospital\": (25.2285, 55.3273),\n    \"Hanoi French Hospital\": (21.003636, 105.840011),\n\n    # Level 3 countries\n    \"Tribhuvan University Teaching Hospital\": (27.7172, 85.3240),\n    \"Norvic International Hospital\": (27.7060, 85.3171),\n    \"Mulago Hospital\": (0.3365, 32.5825),\n    \"International Hospital Kampala\": (0.3031, 32.5950),\n    \"Parirenyatwa General Hospital\": (-17.8292, 31.0522),\n    \"Harare Central Hospital\": (-17.8290, 31.0530),\n    \"Black Lion Hospital\": (9.0326, 38.7468),\n    \"St. Paul's Hospital Millennium Medical College\": (9.0176, 38.7498),\n    \"Korle Bu Teaching Hospital\": (5.5400, -0.2237),\n    \"Nyaho Medical Centre\": (5.6064, -0.1705),\n    \"BIRDEM General Hospital\": (23.7380, 90.3948),\n    \"Square Hospital\": (23.7520, 90.3776),\n    \"National Hospital Abuja\": (9.0539, 7.4919),\n    \"University College Hospital Ibadan\": (7.3878, 3.8966),\n    \"Indus Hospital Karachi\": (24.8615, 67.0099),\n    \"Shifa International Hospital\": (33.6938, 73.0652),\n    \"Yangon General Hospital\": (16.7796, 96.1583),\n    \"Pun Hlaing Hospital\": (16.8213, 96.1011),\n    \"YaoundÃ© Central Hospital\": (3.8480, 11.5021),\n    \"Laquintinie Hospital\": (4.0483, 9.7043),\n    \"CHU-YO (Ouagadougou)\": (12.3615, -1.5339),\n    \"Polyclinique Notre Dame de la Paix\": (12.3751, -1.5123),\n    \"General Hospital of Kinshasa\": (-4.3276, 15.3136),\n    \"Ngaliema Clinic\": (-4.3270, 15.3060),\n    \"Sudan Federal Hospital\": (15.5007, 32.5599),\n    \"Al-Shaab Teaching Hospital\": (15.5895, 32.5519),\n    \"Clinica Los Olivos\": (-17.3926, -66.1605),\n    \"Hospital Univalle\": (-17.3784, -66.1589)\n}\n\n# ... [no changes to get_country_level, extract_coordinates_from_text, find_closest_hospital, generate_map] ...\ncase_directory = \"/kaggle/working/case_files\"\nos.makedirs(case_directory, exist_ok=True)\n\ndef generate_case_number():\n    return f\"GB1-{random.randint(100,999)}-{random.randint(100,999)}\"\n\ndef initialize_case(full_name, home_address, outbound, inbound):\n    case_number = generate_case_number()\n    case = {\n        \"case_number\": case_number,\n        \"full_name\": full_name,\n        \"home_address\": home_address,\n        \"outbound_flight\": outbound,\n        \"return_flight\": inbound,\n        \"created_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n        \"chat_history\": []\n    }\n    with open(f\"{case_directory}/{case_number}.json\", \"w\") as f:\n        json.dump(case, f, indent=4)\n    return case\n\ndef load_case(case_number):\n    path = f\"{case_directory}/{case_number}.json\"\n    if os.path.exists(path):\n        with open(path, \"r\") as f:\n            return json.load(f)\n    return None\n\ndef update_case(case_data):\n    path = f\"{case_directory}/{case_data['case_number']}.json\"\n    with open(path, \"w\") as f:\n        json.dump(case_data, f, indent=4)\n\ndef get_country_level(country):\n    if country in level_1:\n        return \"Level 1\"\n    elif country in level_2:\n        return \"Level 2\"\n    elif country in level_3:\n        return \"Level 3\"\n    return \"Unknown\"\n\ndef extract_coordinates_from_text(text):\n    coords = re.findall(r\"(-?\\d+\\.\\d+),\\s*(-?\\d+\\.\\d+)\", text)\n    if coords:\n        return float(coords[0][0]), float(coords[0][1])\n    return None\n\ndef find_closest_hospital(user_coords):\n    min_dist = float(\"inf\")\n    closest = None\n    for name, coords in hospital_locations.items():\n        dist_km = distance(user_coords, coords).km\n        if dist_km < min_dist:\n            min_dist = dist_km\n            closest = (name, coords, dist_km)\n    return closest\n\ndef generate_map(user_text):\n    coords = extract_coordinates_from_text(user_text)\n    if not coords:\n        return \"<p>No coordinates detected in message.</p>\"\n    closest = find_closest_hospital(coords)\n    if not closest:\n        return \"<p>No hospital found nearby.</p>\"\n    hname, hcoords, dist = closest\n    fmap = folium.Map(location=coords, zoom_start=10)\n    folium.Marker(location=coords, popup=\"Client Location\", icon=folium.Icon(color=\"blue\")).add_to(fmap)\n    folium.Marker(location=hcoords, popup=f\"{hname} ({dist:.1f} km)\", icon=folium.Icon(color=\"green\")).add_to(fmap)\n    tmp_file = tempfile.NamedTemporaryFile(suffix=\".html\", delete=False)\n    fmap.save(tmp_file.name)\n    with open(tmp_file.name, \"r\") as f:\n        return f.read()\n\ndef generate_image_description(image_path):\n    raw_image = Image.open(image_path).convert('RGB')\n    inputs = processor(raw_image, return_tensors=\"pt\")\n    out = model.generate(**inputs)\n    return processor.decode(out[0], skip_special_tokens=True)\n\ndef medical_chat(user_input, image=None, chat_history=[]):\n    system_prompt = {\n        \"role\": \"system\",\n        \"content\": (\n            \"You are an experienced agent working in the Operations or Medical Team \"\n            \"of a travel health insurance company. Respond empathetically and professionally. \"\n            \"Above there is a JSON mapping of *all* our trusted hospitals worldwide, with their coordinates:\"\n            \"Assess whether the hospital mentioned is in a trusted network and recommend next steps accordingly. \"\n            \"Use the list of known countries and hospitals to guide your response. If unclear, ask questions to clarify.\"\n        )\n    }\n\n    lower_input = user_input.lower()\n    country_found = next((c for c in level_1 + level_2 + level_3 if c.lower() in lower_input), None)\n    hospital_found = next((h for h in hospital_locations if h.lower() in lower_input), None)\n\n    guidance = \"\"\n    coords = extract_coordinates_from_text(user_input)\n    if coords:\n        closest = find_closest_hospital(coords)\n        if closest:\n            hname, hcoords, dist_km = closest\n            dist_mi = dist_km * 0.621371\n            transport = \"an ambulance\" if \"severe\" in lower_input or \"bleeding\" in lower_input or \"canâ€™t walk\" in lower_input else \"a taxi\"\n            maps_link = f\"https://www.google.com/maps/dir/{coords[0]},{coords[1]}/{hcoords[0]},{hcoords[1]}\"\n            guidance = (\n                f\"ğŸš‘ Given your injury, it's crucial to seek care quickly. I recommend **{hname}**, \"\n                f\"which is approximately **{dist_mi:.1f} miles** from your current location.\\n\\n\"\n                f\"Please arrange for **{transport}** to take you there.\\n\\n\"\n                f\"ğŸ“ [Click here for directions on Google Maps]({maps_link})\\n\\n\"\n                \"Once you arrive, please confirm admission so we can begin coordinating follow-up care or repatriation if necessary.\"\n            )\n            chat_history.append({\"role\": \"assistant\", \"content\": guidance})\n\n    elif country_found:\n        level = get_country_level(country_found)\n        if level == \"Level 1\":\n            guidance = f\"ğŸŸ¢ {country_found} is a Level 1 country. All hospitals are considered reliable.\"\n        elif hospital_found:\n            guidance = f\"ğŸŸ¢ {hospital_found} in {country_found} is a trusted facility in our network. Care should be appropriate.\"\n        else:\n            guidance = (\n                f\"âš ï¸ {country_found} is a {level} country. If the hospital is not in our trusted network, \"\n                \"we recommend moving the patient to a reliable facility or considering evacuation.\"\n            )\n        chat_history.append({\"role\": \"assistant\", \"content\": guidance})\n\n    if image:\n        image_caption = generate_image_description(image)\n        chat_history.append({\"role\": \"assistant\", \"content\": f\"ğŸ–¼ï¸ Injury analysis: {image_caption}\"})\n        if \"deep\" in image_caption or \"open wound\" in image_caption or \"fracture\" in image_caption:\n            chat_history.append({\"role\": \"assistant\", \"content\": \"âš ï¸ This injury appears serious. Immediate evaluation is required.\"})\n\n    prompt_text = f\"{user_input}\\nImage description: {image_caption}\" if image else user_input\n    messages = [system_prompt] + chat_history + [{\"role\": \"user\", \"content\": prompt_text}]\n\n    try:\n        response = client.chat.completions.create(\n            model=\"gpt-4-turbo\",\n            messages=messages,\n            max_tokens=700\n        )\n        reply = response.choices[0].message.content\n    except Exception as e:\n        print(f\"Error in medical chat: {e}\")\n        return \"Error processing the request.\", chat_history\n\n    chat_history.append({\"role\": \"user\", \"content\": user_input})\n    chat_history.append({\"role\": \"assistant\", \"content\": reply})\n    return reply, chat_history\n\n# --------------------- Onboarding + Case Rules --------------------------\ndef respond(message, image, chat_history, file, name, address, outbound, inbound, onboarded):\n    if not onboarded:\n        if not (name and address and outbound and inbound):\n            return \"â—Please complete onboarding.\", chat_history, chat_history, \"\", onboarded, \\\n                   gr.update(visible=True), gr.update(visible=True), \\\n                   gr.update(visible=True), gr.update(visible=True), \\\n                   gr.update(visible=False)\n\n        case = initialize_case(name, address, outbound, inbound)\n        intro = f\"âœ… Welcome {name}. Your case number is {case['case_number']}. Please use this in future communication.\"\n        chat_history.append({\"role\": \"assistant\", \"content\": intro})\n        save_case(case)\n        return \"\", chat_history, chat_history, \"\", True, \\\n               gr.update(visible=False), gr.update(visible=False), \\\n               gr.update(visible=False), gr.update(visible=False), \\\n               gr.update(visible=True, value=case['case_number'])\n\n    file_text = \"\"\n    if file:\n        file_path = file.name\n        file_text = extract_text_from_file(file_path)\n        if file_text == \"Unsupported file format.\":\n            chat_history.append({\"role\": \"assistant\", \"content\": \"âš ï¸ I couldn't read the contents of the uploaded file. Please check the file format.\"})\n        else:\n            chat_history.append({\"role\": \"user\", \"content\": f\"ğŸ“„ Uploaded Medical Report:\\n{file_text}\"})\n\n    reply, updated_history = medical_chat(message + \"\\n\" + file_text, image, chat_history)\n    map_html = generate_map(message)\n\n    return \"\", updated_history, updated_history, map_html, onboarded, \\\n           gr.update(), gr.update(), gr.update(), gr.update(), gr.update()\n\n\n# ğŸ§  Gradio UI\nwith gr.Blocks() as demo:\n    chatbot = gr.Chatbot(label=\"ğŸ–¾ AI Health Assistant\", type=\"messages\")\n    state = gr.State([])\n    onboarded_state = gr.State(False)\n\n    full_name = gr.Textbox(label=\"ğŸ§‘ Full Name\", visible=True)\n    home_address = gr.Textbox(label=\"ğŸ  Home Address\", visible=True)\n    outbound_flight = gr.Textbox(label=\"ğŸ“… Outbound Flight Date (YYYY-MM-DD)\", visible=True)\n    return_flight = gr.Textbox(label=\"ğŸ“… Return Flight Date (YYYY-MM-DD)\", visible=True)\n    case_id_display = gr.Textbox(label=\"ğŸ“ Case Number\", interactive=False, visible=False)\n\n    with gr.Row():\n        txt = gr.Textbox(label=\"ğŸ’¬ Your Message\", placeholder=\"Describe your injury or ask a question...\")\n        img = gr.Image(type=\"filepath\", label=\"ğŸ“· Upload Injury Photo (optional)\")\n        file = gr.File(label=\"ğŸ“„ Upload Medical Report (PDF/DOCX)\", file_types=[\".pdf\", \".docx\"])\n\n    map_output = gr.HTML(label=\"ğŸŒ Nearest Trusted Medical Facility\")\n    submit = gr.Button(\"Send\")\n\n    submit.click(\n        respond,\n        inputs=[txt, img, state, file, full_name, home_address, outbound_flight, return_flight, onboarded_state],\n        outputs=[txt, chatbot, state, map_output, onboarded_state,\n                 full_name, home_address, outbound_flight, return_flight, case_id_display]\n    )\n\ndemo.launch(share=True)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:35:47.426465Z","iopub.execute_input":"2025-04-19T12:35:47.427355Z","iopub.status.idle":"2025-04-19T12:35:52.006100Z","shell.execute_reply.started":"2025-04-19T12:35:47.427327Z","shell.execute_reply":"2025-04-19T12:35:52.005011Z"}},"outputs":[{"name":"stdout","text":"* Running on local URL:  http://127.0.0.1:7862\n* Running on public URL: https://2fb673e7367d9def85.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://2fb673e7367d9def85.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"## Prompt example: ","metadata":{}},{"cell_type":"markdown","source":"First of all you need to insert your details so that a case reference number it is assigned to you. \n\nFull name: Liam Thompson; Home Address: Street View, Liverpool L1 0AE; Outbound flight: 2025-04-12: Return flight: 2025-04-25.\n\nA Case number will be given. \n\nPrompt options: \n\nOption1: Iâ€™ve had a severe fall and injured my leg. Iâ€™m in need of immediate medical assistance. Can you help?\n\nOption 2: Hi there, this is Liam Thompson, I have just had a terrible accident while on holidays in Da Nang. My coordinates are 16.046444, 108.227064 and I need immediate emdical attention due to having a fracture left leg. I attach you an image so that you can check the severity of the injury.  I need an answer straitght away because it is very urgent.  \n\nOption 3: I attach you a medical report that I have just been given. Thanks","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# SECTION 5.4. Unitest","metadata":{}},{"cell_type":"code","source":"# 1. Define the functions to be tested (These should already exist in your notebook)\nimport os\nimport json\nfrom datetime import datetime\nimport random\nfrom geopy.distance import distance\n\ncase_directory = \"/kaggle/working/case_files\"\nos.makedirs(case_directory, exist_ok=True)\n\ndef generate_case_number():\n    return f\"GB1-{random.randint(100,999)}-{random.randint(100,999)}\"\n\ndef initialize_case(full_name, home_address, outbound, inbound):\n    case_number = generate_case_number()\n    case = {\n        \"case_number\": case_number,\n        \"full_name\": full_name,\n        \"home_address\": home_address,\n        \"outbound_flight\": outbound,\n        \"return_flight\": inbound,\n        \"created_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n        \"chat_history\": []\n    }\n    with open(f\"{case_directory}/{case_number}.json\", \"w\") as f:\n        json.dump(case, f, indent=4)\n    return case\n\ndef load_case(case_number):\n    path = f\"{case_directory}/{case_number}.json\"\n    if os.path.exists(path):\n        with open(path, \"r\") as f:\n            return json.load(f)\n    return None\n\ndef get_country_level(country):\n    level_1 = [\"United States\", \"Canada\", \"United Kingdom\", \"Germany\", \"France\"]\n    level_2 = [\"Mexico\", \"Brazil\", \"Thailand\", \"Vietnam\", \"Turkey\"]\n    level_3 = [\"Nepal\", \"Kenya\", \"Nigeria\", \"Pakistan\", \"Bangladesh\"]\n\n    if country in level_1:\n        return \"Level 1\"\n    elif country in level_2:\n        return \"Level 2\"\n    elif country in level_3:\n        return \"Level 3\"\n    return \"Unknown\"\n\ndef extract_coordinates_from_text(text):\n    coords = re.findall(r\"(-?\\d+\\.\\d+),\\s*(-?\\d+\\.\\d+)\", text)\n    if coords:\n        return float(coords[0][0]), float(coords[0][1])\n    return None\n\n\n# 2. Now, define the Unit Test for those functions\n\nimport unittest\n\nclass TestMedicalAssistantFunctions(unittest.TestCase):\n\n    def setUp(self):\n        # Setup test case directory and data\n        self.case_directory = \"/kaggle/working/case_files\"\n        os.makedirs(self.case_directory, exist_ok=True)\n        \n        self.test_case_data = {\n            \"full_name\": \"John Doe\",\n            \"home_address\": \"123 Test St, Test City\",\n            \"outbound\": \"2025-04-01\",\n            \"inbound\": \"2025-04-10\"\n        }\n    \n    def test_generate_case_number(self):\n        \"\"\"Test case number generation\"\"\"\n        case_number = generate_case_number()\n        self.assertTrue(case_number.startswith(\"GB1-\"))\n        self.assertEqual(len(case_number.split(\"-\")), 3)\n\n    def test_initialize_case(self):\n        \"\"\"Test case initialization and file saving\"\"\"\n        case = initialize_case(self.test_case_data[\"full_name\"], self.test_case_data[\"home_address\"],\n                               self.test_case_data[\"outbound\"], self.test_case_data[\"inbound\"])\n        \n        self.assertIn(\"case_number\", case)\n        case_file_path = f\"{self.case_directory}/{case['case_number']}.json\"\n        self.assertTrue(os.path.exists(case_file_path))\n\n        # Load the case to verify its correctness\n        loaded_case = load_case(case['case_number'])\n        self.assertEqual(loaded_case[\"full_name\"], self.test_case_data[\"full_name\"])\n\n    def test_get_country_level(self):\n        \"\"\"Test country level detection\"\"\"\n        level_1_country = \"United States\"\n        level_2_country = \"Mexico\"\n        level_3_country = \"Nepal\"\n        unknown_country = \"Mars\"\n        \n        self.assertEqual(get_country_level(level_1_country), \"Level 1\")\n        self.assertEqual(get_country_level(level_2_country), \"Level 2\")\n        self.assertEqual(get_country_level(level_3_country), \"Level 3\")\n        self.assertEqual(get_country_level(unknown_country), \"Unknown\")\n\n    def test_extract_coordinates_from_text(self):\n        \"\"\"Test extraction of coordinates from text\"\"\"\n        text_with_coords = \"The hospital is located at 13.7489, 100.5562.\"\n        coordinates = extract_coordinates_from_text(text_with_coords)\n        self.assertEqual(coordinates, (13.7489, 100.5562))\n\n        text_without_coords = \"The hospital is located nearby.\"\n        coordinates = extract_coordinates_from_text(text_without_coords)\n        self.assertIsNone(coordinates)\n\n    def tearDown(self):\n        # Cleanup after tests\n        for filename in os.listdir(self.case_directory):\n            file_path = os.path.join(self.case_directory, filename)\n            os.remove(file_path)\n        os.rmdir(self.case_directory)\n\n# 3. Run the tests\nif __name__ == \"__main__\":\n    unittest.main(argv=[''], verbosity=2, exit=False)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:29:29.761373Z","iopub.execute_input":"2025-04-19T12:29:29.762165Z","iopub.status.idle":"2025-04-19T12:29:29.801295Z","shell.execute_reply.started":"2025-04-19T12:29:29.762126Z","shell.execute_reply":"2025-04-19T12:29:29.799733Z"}},"outputs":[{"name":"stderr","text":"test_extract_coordinates_from_text (__main__.TestMedicalAssistantFunctions.test_extract_coordinates_from_text)\nTest extraction of coordinates from text ... ok\ntest_generate_case_number (__main__.TestMedicalAssistantFunctions.test_generate_case_number)\nTest case number generation ... ok\ntest_get_country_level (__main__.TestMedicalAssistantFunctions.test_get_country_level)\nTest country level detection ... ok\ntest_initialize_case (__main__.TestMedicalAssistantFunctions.test_initialize_case)\nTest case initialization and file saving ... ok\n\n----------------------------------------------------------------------\nRan 4 tests in 0.012s\n\nOK\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"# SECTION 5.5. Debugging with Logging","metadata":{}},{"cell_type":"code","source":"import logging\n\n# Set up logging to file\nlogging.basicConfig(level=logging.DEBUG, filename=\"app_debug.log\", \n                    format=\"%(asctime)s - %(levelname)s - %(message)s\")\n\ndef respond(message, image, chat_history, file, name, address, outbound, inbound, onboarded):\n    logging.debug(f\"Received message: {message}\")\n    logging.debug(f\"Received image: {image}\")\n    logging.debug(f\"Chat history: {chat_history}\")\n    logging.debug(f\"File: {file}\")\n    logging.debug(f\"Name: {name}, Address: {address}, Outbound: {outbound}, Inbound: {inbound}, Onboarded: {onboarded}\")\n\n    # Proceed with your existing code logic...\n    if not onboarded:\n        logging.debug(\"Onboarding in progress.\")\n        if not (name and address and outbound and inbound):\n            logging.warning(\"Incomplete onboarding data.\")\n            return \"â—Please complete onboarding.\", chat_history, chat_history, \"\", onboarded, \\\n                   gr.update(visible=True), gr.update(visible=True), \\\n                   gr.update(visible=True), gr.update(visible=True), \\\n                   gr.update(visible=False)\n\n    # More code logic...\n    logging.debug(\"Processing completed.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:29:29.803405Z","iopub.execute_input":"2025-04-19T12:29:29.804602Z","iopub.status.idle":"2025-04-19T12:29:29.814594Z","shell.execute_reply.started":"2025-04-19T12:29:29.804574Z","shell.execute_reply":"2025-04-19T12:29:29.812735Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# SECTION 5.6: Refactored Code:","metadata":{}},{"cell_type":"code","source":"import os\nimport json\nimport random\nfrom datetime import datetime\nfrom geopy.distance import distance\nimport re\n\n# ğŸŒ Country Levels\nLEVEL_1 = [\"United States\", \"Canada\", \"United Kingdom\", \"Germany\", \"France\", \"Japan\", \"Australia\", \"New Zealand\", \"Sweden\", \"Norway\", \"Netherlands\", \"Switzerland\", \"Italy\", \"Spain\", \"South Korea\", \"Singapore\"]\nLEVEL_2 = [\"Mexico\", \"Brazil\", \"Thailand\", \"Vietnam\", \"Turkey\", \"Malaysia\", \"Costa Rica\", \"Serbia\", \"India\", \"Philippines\", \"China\", \"Chile\", \"South Africa\", \"Indonesia\", \"Egypt\", \"UAE\"]\nLEVEL_3 = [\"Nepal\", \"Kenya\", \"Nigeria\", \"Pakistan\", \"Bangladesh\", \"Ethiopia\", \"Uganda\", \"Myanmar\", \"Cameroon\", \"Burkina Faso\", \"Zimbabwe\", \"DR Congo\", \"Sudan\", \"Ghana\", \"Bolivia\"]\n\n# ğŸ¥ Trusted Hospitals with coordinates\nHOSPITAL_LOCATIONS = {\n    # Level 2 countries\n    \"Bumrungrad International Hospital\": (13.7489, 100.5562),\n    \"Samitivej Hospital\": (13.7300, 100.5684),\n    # Add more hospitals as needed\n}\n\nCASE_DIRECTORY = \"/kaggle/working/case_files\"\nos.makedirs(CASE_DIRECTORY, exist_ok=True)\n\ndef generate_case_number():\n    \"\"\"Generates a unique case number.\"\"\"\n    return f\"GB1-{random.randint(100, 999)}-{random.randint(100, 999)}\"\n\ndef save_case(case_data):\n    \"\"\"Saves case data to a JSON file.\"\"\"\n    file_path = os.path.join(CASE_DIRECTORY, f\"{case_data['case_number']}.json\")\n    with open(file_path, \"w\") as f:\n        json.dump(case_data, f, indent=4)\n\ndef load_case(case_number):\n    \"\"\"Loads case data from a JSON file.\"\"\"\n    file_path = os.path.join(CASE_DIRECTORY, f\"{case_number}.json\")\n    if os.path.exists(file_path):\n        with open(file_path, \"r\") as f:\n            return json.load(f)\n    return None\n\ndef initialize_case(full_name, home_address, outbound, inbound):\n    \"\"\"Initializes a new case and saves it to the file.\"\"\"\n    case_number = generate_case_number()\n    case_data = {\n        \"case_number\": case_number,\n        \"full_name\": full_name,\n        \"home_address\": home_address,\n        \"outbound_flight\": outbound,\n        \"return_flight\": inbound,\n        \"created_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n        \"chat_history\": []\n    }\n    save_case(case_data)\n    return case_data\n\ndef get_country_level(country):\n    \"\"\"Returns the level of the country based on predefined lists.\"\"\"\n    if country in LEVEL_1:\n        return \"Level 1\"\n    elif country in LEVEL_2:\n        return \"Level 2\"\n    elif country in LEVEL_3:\n        return \"Level 3\"\n    return \"Unknown\"\n\ndef extract_coordinates_from_text(text):\n    \"\"\"Extracts coordinates from a string of text.\"\"\"\n    coords = re.findall(r\"(-?\\d+\\.\\d+),\\s*(-?\\d+\\.\\d+)\", text)\n    if coords:\n        return float(coords[0][0]), float(coords[0][1])\n    return None\n\ndef find_closest_hospital(user_coords):\n    \"\"\"Finds the closest hospital based on user coordinates.\"\"\"\n    min_dist = float(\"inf\")\n    closest = None\n    for name, coords in HOSPITAL_LOCATIONS.items():\n        dist_km = distance(user_coords, coords).km\n        if dist_km < min_dist:\n            min_dist = dist_km\n            closest = (name, coords, dist_km)\n    return closest\n\ndef generate_map(user_text):\n    \"\"\"Generates an HTML map showing the user's location and the nearest hospital.\"\"\"\n    coords = extract_coordinates_from_text(user_text)\n    if not coords:\n        return \"<p>No coordinates detected in message.</p>\"\n    closest = find_closest_hospital(coords)\n    if not closest:\n        return \"<p>No hospital found nearby.</p>\"\n    hname, hcoords, dist = closest\n    fmap = folium.Map(location=coords, zoom_start=10)\n    folium.Marker(location=coords, popup=\"Client Location\", icon=folium.Icon(color=\"blue\")).add_to(fmap)\n    folium.Marker(location=hcoords, popup=f\"{hname} ({dist:.1f} km)\", icon=folium.Icon(color=\"green\")).add_to(fmap)\n    tmp_file = tempfile.NamedTemporaryFile(suffix=\".html\", delete=False)\n    fmap.save(tmp_file.name)\n    with open(tmp_file.name, \"r\") as f:\n        return f.read()\n\ndef medical_chat(user_input, image=None, chat_history=[]):\n    \"\"\"Simulates medical chat interaction, generating appropriate responses.\"\"\"\n    system_prompt = {\n        \"role\": \"system\",\n        \"content\": (\n            \"You are an experienced agent working in the Operations or Medical Team \"\n            \"of a travel health insurance company. Respond empathetically and professionally.\"\n        )\n    }\n\n    lower_input = user_input.lower()\n    country_found = next((c for c in LEVEL_1 + LEVEL_2 + LEVEL_3 if c.lower() in lower_input), None)\n    hospital_found = next((h for h in HOSPITAL_LOCATIONS if h.lower() in lower_input), None)\n\n    guidance = \"\"\n    coords = extract_coordinates_from_text(user_input)\n    if coords:\n        closest = find_closest_hospital(coords)\n        if closest:\n            hname, hcoords, dist_km = closest\n            dist_mi = dist_km * 0.621371\n            transport = \"an ambulance\" if \"severe\" in lower_input or \"bleeding\" in lower_input or \"canâ€™t walk\" in lower_input else \"a taxi\"\n            maps_link = f\"https://www.google.com/maps/dir/{coords[0]},{coords[1]}/{hcoords[0]},{hcoords[1]}\"\n            guidance = (\n                f\"ğŸš‘ Given your injury, it's crucial to seek care quickly. I recommend **{hname}**, \"\n                f\"which is approximately **{dist_mi:.1f} miles** from your current location.\\n\\n\"\n                f\"Please arrange for **{transport}** to take you there.\\n\\n\"\n                f\"ğŸ“ [Click here for directions on Google Maps]({maps_link})\\n\\n\"\n                \"Once you arrive, please confirm admission so we can begin coordinating follow-up care or repatriation if necessary.\"\n            )\n            chat_history.append({\"role\": \"assistant\", \"content\": guidance})\n\n    elif country_found:\n        level = get_country_level(country_found)\n        if level == \"Level 1\":\n            guidance = f\"ğŸŸ¢ {country_found} is a Level 1 country. All hospitals are considered reliable.\"\n        elif hospital_found:\n            guidance = f\"ğŸŸ¢ {hospital_found} in {country_found} is a trusted facility in our network. Care should be appropriate.\"\n        else:\n            guidance = (\n                f\"âš ï¸ {country_found} is a {level} country. If the hospital is not in our trusted network, \"\n                \"we recommend moving the patient to a reliable facility or considering evacuation.\"\n            )\n        chat_history.append({\"role\": \"assistant\", \"content\": guidance})\n\n    if image:\n        image_caption = generate_image_description(image)\n        chat_history.append({\"role\": \"assistant\", \"content\": f\"ğŸ–¼ï¸ Injury analysis: {image_caption}\"})\n        if \"deep\" in image_caption or \"open wound\" in image_caption or \"fracture\" in image_caption:\n            chat_history.append({\"role\": \"assistant\", \"content\": \"âš ï¸ This injury appears serious. Immediate evaluation is required.\"})\n\n    prompt_text = f\"{user_input}\\nImage description: {image_caption}\" if image else user_input\n    messages = [system_prompt] + chat_history + [{\"role\": \"user\", \"content\": prompt_text}]\n    response = client.chat.completions.create(\n        model=\"gpt-4-turbo\",\n        messages=messages,\n        max_tokens=700\n    )\n\n    reply = response.choices[0].message.content\n    chat_history.append({\"role\": \"user\", \"content\": user_input})\n    chat_history.append({\"role\": \"assistant\", \"content\": reply})\n    return reply, chat_history\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:29:29.816609Z","iopub.execute_input":"2025-04-19T12:29:29.817007Z","iopub.status.idle":"2025-04-19T12:29:29.847264Z","shell.execute_reply.started":"2025-04-19T12:29:29.816980Z","shell.execute_reply":"2025-04-19T12:29:29.846101Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"# -----------------------------------\n# ğŸ“š SECTION 6: References\n# -----------------------------------","metadata":{}},{"cell_type":"code","source":"references = [\n    \"ğŸ“„ Prompt Engineering Whitepaper â€“ Google Cloud\",\n    \"ğŸ“„ Solving Domain-Specific Problems using LLMs â€“ Google Cloud\",\n    \"ğŸ“„ Operationalizing Generative AI on Vertex AI â€“ Google Cloud\",\n    \"ğŸ“„ Agents Whitepaper â€“ Google Cloud\",\n    \"ğŸ“„ Agents Companion Guide â€“ Vertex AI\",\n    \"ğŸ“š LangChain & LangGraph Documentation â€“ https://docs.langchain.com/\",\n    \"ğŸ CrewAI Multi-Agent Framework â€“ https://docs.crewai.io/\",\n    \"ğŸ† Kaggle Competition: 5-Day Generative AI Intensive by Google & DeepMind (2025)\",\n    \"ğŸ§  L1â€“L6 Notebooks from Googleâ€™s Gen AI Capstone on Kaggle\",\n    \"ğŸ“ Internal Medical Protocols & ACC Guidelines (uploaded images)\",\n    \"ğŸ’» Gemini Model API â€“ via Google Vertex AI\",\n    \"ğŸ§ª Streamlit + Gradio for Agent Simulation UI\",\n    \"ğŸ”’ GDPR Guidelines â€“ EU Data Protection Regulation\",\n    \"ğŸ“¦ Full project source: https://github.com/OYanez85/5-Day_Gen_AI_Intensive_by_Kaggle_and_Goggle_Deep_Mind_2025\",\n    \"ğŸ“‚ CSV Logs stored in: /kaggle/working/conversation_log.csv\"\n]\n\nprint(\"\\n--- ğŸ“š References ---\")\nfor ref in references:\n    print(f\"- {ref}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:29:29.848880Z","iopub.execute_input":"2025-04-19T12:29:29.849182Z","iopub.status.idle":"2025-04-19T12:29:29.876567Z","shell.execute_reply.started":"2025-04-19T12:29:29.849159Z","shell.execute_reply":"2025-04-19T12:29:29.875526Z"}},"outputs":[{"name":"stdout","text":"\n--- ğŸ“š References ---\n- ğŸ“„ Prompt Engineering Whitepaper â€“ Google Cloud\n- ğŸ“„ Solving Domain-Specific Problems using LLMs â€“ Google Cloud\n- ğŸ“„ Operationalizing Generative AI on Vertex AI â€“ Google Cloud\n- ğŸ“„ Agents Whitepaper â€“ Google Cloud\n- ğŸ“„ Agents Companion Guide â€“ Vertex AI\n- ğŸ“š LangChain & LangGraph Documentation â€“ https://docs.langchain.com/\n- ğŸ CrewAI Multi-Agent Framework â€“ https://docs.crewai.io/\n- ğŸ† Kaggle Competition: 5-Day Generative AI Intensive by Google & DeepMind (2025)\n- ğŸ§  L1â€“L6 Notebooks from Googleâ€™s Gen AI Capstone on Kaggle\n- ğŸ“ Internal Medical Protocols & ACC Guidelines (uploaded images)\n- ğŸ’» Gemini Model API â€“ via Google Vertex AI\n- ğŸ§ª Streamlit + Gradio for Agent Simulation UI\n- ğŸ”’ GDPR Guidelines â€“ EU Data Protection Regulation\n- ğŸ“¦ Full project source: https://github.com/OYanez85/5-Day_Gen_AI_Intensive_by_Kaggle_and_Goggle_Deep_Mind_2025\n- ğŸ“‚ CSV Logs stored in: /kaggle/working/conversation_log.csv\n","output_type":"stream"}],"execution_count":17}]}